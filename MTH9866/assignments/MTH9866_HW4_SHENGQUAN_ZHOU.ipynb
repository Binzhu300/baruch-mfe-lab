{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MTH9866 Modeling and Market Making in Foreign Exchange\n",
    "\n",
    "#### Homework Assignment 4\n",
    "\n",
    "#### ShengQuan Zhou"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1\n",
    "\n",
    "The current time is Wednesday at 1pm and you see the overnight implied volatility (for 10am expiration on Thursday) trading at 9%. The FX markets are open for trading every hour between now and tomorrow at 10am.\n",
    "\n",
    "The Federal Reserve Chairwoman is speaking about the economy from 2-3pm, and that event adds an extra 0.5 trading days worth of variance on top of the usual variance for that time period.\n",
    "\n",
    "What should the overnight implied volatility be at 3pm, all else being equal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "The key insight is that the cumulative variance $\\sigma^2 T$ is a dimensionless quantity and should be independent of time-scale chosen. If $T$ is the calendar time, then $\\sigma$ is calendar time volatility; if $T$ is trading time, then $\\sigma$ is trading time volatility. In both cases, $\\sigma^2 T$ should be the same.\n",
    "\n",
    "Given the fact that Wednesday at 1pm, the overnight implied volatility for 10am expiration trading at 9%,\n",
    "$$\n",
    "\\sigma^2_{c} T_c =  \\frac{0.09^2}{365} \\approx 2.2191\\times 10^{-5}.\n",
    "$$\n",
    "Since the FX markets are open for trading every hour between 1pm and tomorrow at 10am, the trading time in-between is 21 hours, plus 0.5 trading days, or equivalently 12 hours, from the extra variance due to the Federal Reserve event. So the trading time is 33 hours and the corresponding hourly volatility is determined by\n",
    "$$\n",
    "\\sigma^2_t T_t = \\sigma^2_c T_c \\Rightarrow \\sigma_t = \\sigma_c\\sqrt{\\frac{T_c}{T_t}} = 0.09\\times\\sqrt{\\frac{1}{365\\times 33}}\n",
    "\\approx 8.2\\times 10^{-4}.\n",
    "$$\n",
    "After the event at 3pm, not only the calendar times has passed 2 hours, but also the trading time has passed 12 hours. So the remaining trading time until tomorrow 10am is 19 hours. **The trading time volatility is assumed to be constant over time**. Thus, the cumulative variance for the remaining 19 hours is\n",
    "$$\n",
    "\\sigma'^2_t T'_t = \\frac{0.09^2}{365\\times 33}\\times 19 \\approx 1.278\\times 10^{-5}.\n",
    "$$\n",
    "Finally, we convert back to calendar time, where $T_c'$ is still $\\frac{1}{365}$:\n",
    "$$\n",
    "\\sigma'^2_c T'_c = \\sigma'^2_t T'_t \\Rightarrow \\sigma_c' = \\sigma_t'\\sqrt{\\frac{T'_t}{T'_c}} = 0.09\\times\\sqrt{\\frac{19}{33}} \\approx 6.83\\%.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "\n",
    "In stochastic volatility models, why is there a smile? Describe the genesis of the smile in terms of vega gamma.\n",
    "\n",
    "Similarly, describe why stochastic volatility models generate a skew, in terms of vega dspot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "- Smile comes from volatility of volatility, combined with the symmetric vega gamma $\\frac{\\partial^2}{\\partial \\sigma^2}$ profile of vanilla options.\n",
    "> - Buy a high-strike or a low-strike vanilla $\\Rightarrow$ a position that is long vega gamma and long vega. \n",
    "> - Sell a certain amount of ATM vanilla options to vega hedge the position; ATM options have zero vega gamma $\\Rightarrow$ the position is still long vega gamma. \n",
    "> - In other words, whichever way vol moves, one makes money. \n",
    "> - Thus, traders tend to buy up high- and low-strike options and sell ATM options, which increases implied volatilities for high- and low-strike options vs the ATM implied volatility. \n",
    "> - As a consequence, the market pressure creates the implied volatility smile \n",
    "> - Implied volatility smile is a symmetric smile because vega gamma is positive for both high- and low-strike options.\n",
    "\n",
    "- Skew comes from spot/vol correlation, combined with the asymmetric vega dspot $\\frac{\\partial^2}{\\partial\\sigma\\partial S}$ profile of vanilla options.\n",
    "> - Assume spot/vol correlation is positive: buy a high-strike option $\\Rightarrow$ a position with long vega dspot and long vega. \n",
    "> - Sell a certain amount of ATM vanilla options to hedge vega; ATM options have zero vega dspot $\\Rightarrow$ the position is long vega dspot and flat vega. \n",
    "> - Then if spot goes up, your vega turns positive; and vol goes up because of the positive correlation $\\Rightarrow \\frac{\\partial V}{\\partial \\sigma}\\Delta \\sigma>0$ make money. \n",
    "> - Similarly if spot goes down, vega turns negative; and vol goes down because of the positive correlation $\\Rightarrow \\frac{\\partial V}{\\partial \\sigma}\\Delta \\sigma>0$ make money.\n",
    "> - Thus, traders tend to buy high-strike options and sell low-strike options, which increases implied volatilities for the high-strike options and reduces implied volatilities of low-strike options.\n",
    "> - As a consequence, the market pressure creates the positive implied volatility skew.\n",
    "> - If spot/vol correlation is negative, all the signs change, and traders tend to sell high-strike options and buy low-strike options, creating a negative implied volatility skew.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3\n",
    "\n",
    "Why do most FX shops use a “sticky delta” volatility market model when defining delta for hedging purposes, even though that might not give the most accurate estimate of how implied volatilities, and hence portfolio prices, change when spot moves?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Answer:\n",
    "\n",
    "That depends on market convention. It is the market data inputs the risk managers conventionally use that are treated as the main risk variables.\n",
    "\n",
    "In the FX markets, implied volatility trades in the inter-dealer market in terms of delta, for example, ATM vol, 25d risk reversal, 25d butterfly, 10d risk reversal, and 10d butterfly are the traded market variables. As a consequence, traders tend to look at the movement of portfolio risks in terms of market input: spot, keeping vol-by-delta constant; ATM vol, keeping spot and RR/BF constant; and RR/BF, keeping ATM vol and spot constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n",
    "\n",
    "Consider an ATM EURGBP option with 0.5y to expiration. Assume the EURGBP ATM volatility is 3.5%, the EURUSD ATM volatility is 8.5%, and the GBPUSD ATM volatility is 7.5%. What is the implied correlation between EURUSD and GBPUSD spots?\n",
    "\n",
    "EURUSD spot is 1.25 and GBPUSD spot is 1.56; assume zero interest rates.\n",
    "\n",
    "Use the Black-Scholes vega formula to calculate the vegas of all three options and determine the notionals of EURUSD and GBPUSD options needed to hedge the vegas of 1 EUR notional of the EURGBP option, assuming correlation stays constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solution:\n",
    "\n",
    "First estimate the implied correlation between EURUSD and GBPUSD spots:\n",
    "$$\n",
    "\\sigma_{X}^2 = \\sigma_1^2 + \\sigma_2^2 -2\\rho \\sigma_1\\sigma_2 \\Rightarrow \\rho =  \\frac{  \\sigma_1^2 + \\sigma_2^2 - \\sigma_{X}^2}{2\\sigma_1\\sigma_2} = \\frac{  8.5^2 + 7.5^2 - 3.5^2 }{2\\times 8.5\\times 7.5} \\approx 91.2\\%.\n",
    "$$\n",
    "Assuming constant correlation\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial \\sigma_X}{\\partial \\sigma_1} &=& \\frac{\\sigma_1 - \\rho \\sigma_2}{\\sigma_X} \\approx +0.4748, \\\\\n",
    "\\frac{\\partial \\sigma_X}{\\partial \\sigma_2} &=& \\frac{\\sigma_2 - \\rho \\sigma_1}{\\sigma_X} \\approx -0.0714.\n",
    "\\end{eqnarray}\n",
    "ATM strikes\n",
    "\\begin{eqnarray}\n",
    "K_1 &=& F_1 e^{\\frac{1}{2}\\sigma_1^2 T} = 1.25 e^{0.5\\times 0.085^2\\times 0.5}\\approx 1.2523,\\\\\n",
    "K_2 &=& F_2 e^{\\frac{1}{2}\\sigma_2^2 T} = 1.56 e^{0.5\\times 0.075^2\\times 0.5}\\approx 1.5622,\\\\\n",
    "K_X &=& F_X e^{\\frac{1}{2}\\sigma_X^2 T} = \\frac{1.56}{1.25} e^{0.5\\times 0.035^2\\times 0.5}\\approx 1.2484.\n",
    "\\end{eqnarray}\n",
    "Vegas according to Black-Scholes formula: $\\frac{\\partial V}{\\partial \\sigma} = F\\sqrt{\\frac{T}{2\\pi}}e^{-\\frac{1}{2}d_+^2-QT}$, where the ATM strike $K = F e^{\\frac{1}{2}\\sigma^2 T}$\n",
    "$$\n",
    "d_+ = \\frac{1}{\\sigma\\sqrt{T}} \\left[ \\log\\frac{F}{K} + \\left( R-Q + \\frac{1}{2}\\sigma^2 \\right)T \\right]\n",
    "= \\frac{(R-Q)T}{\\sigma\\sqrt{T}},\n",
    "$$\n",
    "Thus, assuming zero interest rate $R=Q=0$, $\\frac{\\partial V}{\\partial \\sigma} = F\\sqrt{\\frac{T}{2\\pi}}$:\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial V_1}{\\partial \\sigma_1} &=& 1.25\\sqrt{\\frac{0.5}{2\\pi}}\\approx 0.3526,\\\\\n",
    "\\frac{\\partial V_2}{\\partial \\sigma_2} &=& 1.56\\sqrt{\\frac{0.5}{2\\pi}}\\approx 0.4401,\\\\\n",
    "\\frac{\\partial V_X}{\\partial \\sigma_X} &=& \\frac{1.56}{1.25}\\sqrt{\\frac{0.5}{2\\pi}}\\approx 0.3521.\n",
    "\\end{eqnarray}\n",
    "Sensitivities of EURGBP with respect to $\\sigma_1$ and $\\sigma_2$:\n",
    "\\begin{eqnarray}\n",
    "\\frac{\\partial V_X}{\\partial \\sigma_1} &=& \\frac{\\partial V_X}{\\partial \\sigma_X}\\frac{\\partial \\sigma_X}{\\partial \\sigma_1} = \\frac{\\partial V_X}{\\partial \\sigma_X}\\frac{\\sigma_1 - \\rho \\sigma_2}{\\sigma_X} \\approx 0.3521\\times 0.4748 \\approx 0.1672,\\\\\n",
    "\\frac{\\partial V_X}{\\partial \\sigma_2} &=& \\frac{\\partial V_X}{\\partial \\sigma_X}\\frac{\\partial \\sigma_X}{\\partial \\sigma_2} = \\frac{\\partial V_X}{\\partial \\sigma_X}\\frac{\\sigma_2 - \\rho \\sigma_1}{\\sigma_X} \\approx 0.3521\\times (-0.0714) \\approx -0.0251.\n",
    "\\end{eqnarray}\n",
    "Hedge quantity:\n",
    "\\begin{eqnarray}\n",
    "Q_1 \\frac{\\partial V_1}{\\partial \\sigma_1} &=& F_X \\frac{\\partial V_X}{\\partial \\sigma_1}\\Rightarrow Q_1 = F_X \\frac{\\partial V_X}{\\partial \\sigma_1} \\big/ \\frac{\\partial V_1}{\\partial \\sigma_1} \\approx 0.5918,\\\\\n",
    "Q_2 \\frac{\\partial V_2}{\\partial \\sigma_2} &=& F_X \\frac{\\partial V_X}{\\partial \\sigma_2}\\Rightarrow Q_2 = F_X \\frac{\\partial V_X}{\\partial \\sigma_2} \\big/ \\frac{\\partial V_2}{\\partial \\sigma_2} \\approx -0.0712,\n",
    "\\end{eqnarray}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "\n",
    "In this question you will look at implied correlations and see how much moves in implied correlation contribute to moves in cross volatility, versus moves in the underlying USD-pair volatilities.\n",
    "\n",
    "Consider the AUDJPY market, where the underlying USD pairs are AUDUSD and USDJPY. \n",
    "\n",
    "For a given expiration tenor, one can calculate the market-implied correlation between moves in AUDUSD spot and USDJPY spot through the implied volatilities for the three pairs.\n",
    "\n",
    "First step: write code to calculate these correlations in a window from 1Jan2007 to 31May2013. I have posted a spreadsheet with the ATM implied volatilities for AUDUSD, USDJPY, and AUDJPY for various expiration tenors on the class forum.\n",
    "\n",
    "You should write a function that takes in the names of the three pairs (as strings like ‘AUDJPY’, ‘AUDUSD’, and ‘USDJPY’), a string tenor (like ‘3m’), a flag to define whether the cross spot is the product or the ratio of the two USD spots (which affects the sign of the correlation), and the start and end dates of the historical window.\n",
    "\n",
    "It should start by loading the data for the ATM implied volatility for the four tenors from the spreadsheet into pandas DataFrames and then calculate a pandas DataFrame of implied correlations.\n",
    "\n",
    "The next step: use the correlation from date i, along with the implied volatilities for the USD pairs on date i+1, to predict the cross volatility on date i+1. Do this with the pandas DataFrames you have already created.\n",
    "\n",
    "Finally, construct two DataFrames: one holding day-to-day changes in the cross ATM volatility, and one holding differences between the predicted cross volatility (assuming the implied correlation from the day before) and the true cross volatility.\n",
    "\n",
    "The function should print out statistics on both those series.\n",
    "\n",
    "Run this for the following list of tenors: 1w, 1m, 6m, and 1y. Comment on any differences across tenors, and whether this seems like a good hedging strategy for hedging AUDJPY volatility. Make sure to refer to statistics of the two series, both standard deviations as well as maximum and minimum deviations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fxVolData = pd.read_excel(\"fx_vol_data.xlsx\", index=\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AUDUSD 1w</th>\n",
       "      <th>AUDUSD 1m</th>\n",
       "      <th>AUDUSD 6m</th>\n",
       "      <th>AUDUSD 1y</th>\n",
       "      <th>USDJPY 1w</th>\n",
       "      <th>USDJPY 1m</th>\n",
       "      <th>USDJPY 6m</th>\n",
       "      <th>USDJPY 1y</th>\n",
       "      <th>AUDJPY 1w</th>\n",
       "      <th>AUDJPY 1m</th>\n",
       "      <th>AUDJPY 6m</th>\n",
       "      <th>AUDJPY 1y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2007-01-02</td>\n",
       "      <td>7.5000</td>\n",
       "      <td>7.1500</td>\n",
       "      <td>7.1750</td>\n",
       "      <td>7.3250</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>6.5500</td>\n",
       "      <td>6.75000</td>\n",
       "      <td>6.90000</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2007-01-03</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>7.2750</td>\n",
       "      <td>7.3250</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>6.8000</td>\n",
       "      <td>6.3000</td>\n",
       "      <td>6.62500</td>\n",
       "      <td>6.85000</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2007-01-04</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>7.4100</td>\n",
       "      <td>7.4300</td>\n",
       "      <td>7.0018</td>\n",
       "      <td>6.7006</td>\n",
       "      <td>6.85045</td>\n",
       "      <td>6.92543</td>\n",
       "      <td>6.75</td>\n",
       "      <td>6.4</td>\n",
       "      <td>7.15</td>\n",
       "      <td>7.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2007-01-05</td>\n",
       "      <td>7.7522</td>\n",
       "      <td>7.3007</td>\n",
       "      <td>7.4006</td>\n",
       "      <td>7.4506</td>\n",
       "      <td>6.8000</td>\n",
       "      <td>6.9500</td>\n",
       "      <td>6.90000</td>\n",
       "      <td>6.92000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2007-01-08</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>7.3000</td>\n",
       "      <td>7.4000</td>\n",
       "      <td>6.7500</td>\n",
       "      <td>6.7250</td>\n",
       "      <td>6.85000</td>\n",
       "      <td>6.95000</td>\n",
       "      <td>7.50</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.30</td>\n",
       "      <td>7.40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AUDUSD 1w  AUDUSD 1m  AUDUSD 6m  AUDUSD 1y  USDJPY 1w  \\\n",
       "0 2007-01-02     7.5000     7.1500     7.1750     7.3250     7.0000   \n",
       "1 2007-01-03     7.9250     7.2750     7.3250     7.4000     6.8000   \n",
       "2 2007-01-04     7.7500     7.2500     7.4100     7.4300     7.0018   \n",
       "3 2007-01-05     7.7522     7.3007     7.4006     7.4506     6.8000   \n",
       "4 2007-01-08     7.0500     7.3000     7.3000     7.4000     6.7500   \n",
       "\n",
       "   USDJPY 1m  USDJPY 6m  USDJPY 1y  AUDJPY 1w  AUDJPY 1m  AUDJPY 6m  AUDJPY 1y  \n",
       "0     6.5500    6.75000    6.90000       6.75        6.4       7.15       7.55  \n",
       "1     6.3000    6.62500    6.85000       6.75        6.4       7.15       7.55  \n",
       "2     6.7006    6.85045    6.92543       6.75        6.4       7.15       7.55  \n",
       "3     6.9500    6.90000    6.92000       7.50        7.5       7.30       7.40  \n",
       "4     6.7250    6.85000    6.95000       7.50        7.5       7.30       7.40  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fxVolData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class CrossFxVolAnalyzer:\n",
    "    \"\"\"\n",
    "    An analyzer that \n",
    "    (1) computes implied correlation; \n",
    "    (2) predicts the next-day implied volatility assuming the implied correlation from the day before,\n",
    "    for cross currency pair based the USD pairs.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        self.df = data\n",
    "        \n",
    "    def analyze(self, xPair, pair1, pair2, tenor):\n",
    "        \"\"\"\n",
    "            xPair: cross pair\n",
    "            pair1: first USD pair\n",
    "            pair2: second USD pair\n",
    "            tenor: implied volatility tenor\n",
    "            \n",
    "            Note: whether the cross pair is a ratio or a product \n",
    "                  is determined from the name string of cross pair, \n",
    "                  pair #1 and pair #2, instead of specified otherwise.\n",
    "        \"\"\"\n",
    "        \n",
    "        xCol = xPair + ' ' + tenor\n",
    "        col1 = pair1 + ' ' + tenor\n",
    "        col2 = pair2 + ' ' + tenor\n",
    "        \n",
    "        xPairAsset = xPair[:3]\n",
    "        xPairDenom = xPair[-3:]\n",
    "        pair1Asset = pair1[:3]\n",
    "        pair1Denom = pair1[-3:]\n",
    "        pair2Asset = pair2[:3]\n",
    "        pair2Denom = pair2[-3:]\n",
    "        \n",
    "        # compute implied correlation based on implied vol\n",
    "        impliedCorr = (self.df[col1]**2 + self.df[col2]**2 - self.df[xCol]**2) / (2.0 * self.df[col1] * self.df[col2])\n",
    "        # if the two USD pairs are quote in different denominators, \n",
    "        # use product instead of ratio to form the cross pair.\n",
    "        if (pair1Asset == \"USD\" and pair2Denom == \"USD\") or (pair1Denom == \"USD\" and pair2Asset == \"USD\"):\n",
    "            impliedCorr *= -1\n",
    "        \n",
    "        # predicted the next-day correlation based on the current implied correlation\n",
    "        predictedCorr = np.sqrt(self.df[col1]**2 + self.df[col2]**2 + 2 * impliedCorr.shift(1) * self.df[col1] * self.df[col2])\n",
    "        # estimation error relative the actual cross pair implied vol\n",
    "        estimateDiff = predictedCorr - self.df[xCol]\n",
    "        # daily change of the actual cross pair implied vol\n",
    "        dailyChange = self.df[xCol].shift(1) - self.df[xCol]\n",
    "        \n",
    "        return (estimateDiff.std(), estimateDiff.max(), estimateDiff.min(), dailyChange.std(), dailyChange.max(), dailyChange.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fxAnalyzer = CrossFxVolAnalyzer(fxVolData)\n",
    "xPair = 'AUDJPY'\n",
    "pair1 = 'AUDUSD'\n",
    "pair2 = 'USDJPY'\n",
    "tenors = ['1w', '1m', '6m', '1y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tenor</th>\n",
       "      <th>Predicted Change Std</th>\n",
       "      <th>Predicted Change Max</th>\n",
       "      <th>Predicted Change Min</th>\n",
       "      <th>Actual Change Std</th>\n",
       "      <th>Actual Change Max</th>\n",
       "      <th>Actual Change Min</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1w</td>\n",
       "      <td>1.186038</td>\n",
       "      <td>14.951415</td>\n",
       "      <td>-13.923782</td>\n",
       "      <td>1.795480</td>\n",
       "      <td>1.795480</td>\n",
       "      <td>-18.8050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1m</td>\n",
       "      <td>0.742401</td>\n",
       "      <td>7.866179</td>\n",
       "      <td>-7.311626</td>\n",
       "      <td>1.096523</td>\n",
       "      <td>1.096523</td>\n",
       "      <td>-12.5475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6m</td>\n",
       "      <td>0.383226</td>\n",
       "      <td>5.884164</td>\n",
       "      <td>-3.415851</td>\n",
       "      <td>0.575049</td>\n",
       "      <td>0.575049</td>\n",
       "      <td>-4.9225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1y</td>\n",
       "      <td>0.315963</td>\n",
       "      <td>4.605420</td>\n",
       "      <td>-3.265282</td>\n",
       "      <td>0.431407</td>\n",
       "      <td>0.431407</td>\n",
       "      <td>-3.7175</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  tenor  Predicted Change Std  Predicted Change Max  Predicted Change Min  \\\n",
       "0    1w              1.186038             14.951415            -13.923782   \n",
       "1    1m              0.742401              7.866179             -7.311626   \n",
       "2    6m              0.383226              5.884164             -3.415851   \n",
       "3    1y              0.315963              4.605420             -3.265282   \n",
       "\n",
       "   Actual Change Std  Actual Change Max  Actual Change Min  \n",
       "0           1.795480           1.795480           -18.8050  \n",
       "1           1.096523           1.096523           -12.5475  \n",
       "2           0.575049           0.575049            -4.9225  \n",
       "3           0.431407           0.431407            -3.7175  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['tenor'] = tenors\n",
    "predictedChangeStdList = []\n",
    "predictedChangeMaxList = []\n",
    "predictedChangeMinList = []\n",
    "actualChangeStdList = []\n",
    "actualChangeMaxList = []\n",
    "actualChangeMinList = []\n",
    "\n",
    "for tenor in tenors:\n",
    "    \n",
    "    (predictedChangeStd, predictedChangeMax, predictedChangeMin, actualChangeStd, actualChangeMax, actualChangeMin) = fxAnalyzer.analyze(xPair, pair1, pair2, tenor)\n",
    "    \n",
    "    predictedChangeStdList.append(predictedChangeStd)\n",
    "    predictedChangeMaxList.append(predictedChangeMax)\n",
    "    predictedChangeMinList.append(predictedChangeMin)\n",
    "    actualChangeStdList.append(actualChangeStd)\n",
    "    actualChangeMaxList.append(actualChangeStd)\n",
    "    actualChangeMinList.append(actualChangeMin)\n",
    "    \n",
    "df['Predicted Change Std'] = predictedChangeStdList\n",
    "df['Predicted Change Max'] = predictedChangeMaxList\n",
    "df['Predicted Change Min'] = predictedChangeMinList\n",
    "df['Actual Change Std'] = actualChangeStdList\n",
    "df['Actual Change Max'] = actualChangeMaxList\n",
    "df['Actual Change Min'] = actualChangeMinList\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments\n",
    "\n",
    "- The way of hedging works better for shorter tenors than longer tenors;\n",
    "- For intermediate tenors, standard deviation is reduced, but max/min moves are worse than unhedged;\n",
    "- For very short tenors like 1w, the standard deviation is reduced by only 1/3.\n",
    "\n",
    "In general, assuming that the implied correlation does not move day to day is not a very effective hedging strategy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
