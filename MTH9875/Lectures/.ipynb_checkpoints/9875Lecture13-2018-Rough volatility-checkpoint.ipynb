{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# MTH 9875 The Volatility Surface:    Fall 2018\n",
    "<p>\n",
    "\n",
    "### Lecture 13: Rough volatility\n",
    "<p>\n",
    "\n",
    "Jim Gatheral   \n",
    "Department of Mathematics     \n",
    "\n",
    "  \n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2016/04/MFE-Logo.jpg\" align = \"right\" width=500></h3>\n",
    "\n",
    "$$\n",
    "\\newcommand{\\beas}{\\begin{eqnarray*}}\n",
    "\\newcommand{\\eeas}{\\end{eqnarray*}}\n",
    "\\newcommand{\\bea}{\\begin{eqnarray}}\n",
    "\\newcommand{\\eea}{\\end{eqnarray}}\n",
    "\\newcommand{\\ben}{\\begin{enumerate}}\n",
    "\\newcommand{\\een}{\\end{enumerate}}\n",
    "\\newcommand{\\bi}{\\begin{itemize}}\n",
    "\\newcommand{\\ei}{\\end{itemize}}\n",
    "\\newcommand{\\beq}{\\begin{equation}}\n",
    "\\newcommand{\\eeq}{\\end{equation}}\n",
    "\\newcommand{\\bv}{\\begin{verbatim}}\n",
    "\\newcommand{\\ev}{\\end{verbatim}}\n",
    "\\newcommand{\\E}{\\mathbb{E}}\n",
    "\\newcommand{\\R}{\\mathbb{R}}\n",
    "\\newcommand{\\mP}{\\mathbb{P}}\n",
    "\\newcommand{\\mQ}{\\mathbb{Q}}\n",
    "\\newcommand{\\sigl}{\\sigma_L}\n",
    "\\newcommand{\\BS}{\\rm BS}\n",
    "\\newcommand{\\vix}{\\text{VIX}}\n",
    "\\newcommand{\\p}{\\partial}\n",
    "\\newcommand{\\var}{{\\rm var}}\n",
    "\\newcommand{\\cov}{{\\rm cov}}\n",
    "\\newcommand{\\mt}{\\mathbf{t}}\n",
    "\\newcommand{\\mS}{\\mathbf{S}}\n",
    "\\newcommand{\\tC}{\\widetilde{C}}\n",
    "\\newcommand{\\hC}{\\widehat{C}}\n",
    "\\newcommand{\\cE}{\\mathcal{E}}\n",
    "\\newcommand{\\tH}{\\widetilde{H}}\n",
    "\\newcommand{\\cD}{\\mathcal{D}}\n",
    "\\newcommand{\\cM}{\\mathcal{M}}\n",
    "\\newcommand{\\cS}{\\mathcal{S}}\n",
    "\\newcommand{\\cR}{\\mathcal{R}}\n",
    "\\newcommand{\\cF}{\\mathcal{F}}\n",
    "\\newcommand{\\cV}{\\mathcal{V}}\n",
    "\\newcommand{\\cG}{\\mathcal{G}}\n",
    "\\newcommand{\\cv}{\\mathcal{v}}\n",
    "\\newcommand{\\cg}{\\mathcal{g}}\n",
    "\\newcommand{\\cL}{\\mathcal{L}}\n",
    "\\newcommand{\\cO}{\\mathcal{O}}\n",
    "\\newcommand{\\dt}{\\Delta t}\n",
    "\\newcommand{\\tr}{{\\rm tr}}\n",
    "\\newcommand{\\sgn}{\\mathrm{sign}}\n",
    "\\newcommand{\\ee}[1]{{\\mathbb{E}\\left[{#1}\\right]}}\n",
    "\\newcommand{\\eef}[1]{{\\mathbb{E}\\left[\\left.{#1}\\right|\\cF_t\\right]}}\n",
    "\\newcommand{\\eefm}[2]{{\\mathbb{E}^{#2}\\left[\\left.{#1}\\right|\\cF_t\\right]}}\n",
    "\\newcommand{\\angl}[1]{{\\langle{#1}\\rangle}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Outline of Lecture 13\n",
    "\n",
    "* The time series of historical volatility\n",
    "    - Scaling properties\n",
    "\n",
    "\n",
    "* The RFSV model\n",
    "\n",
    "\n",
    "* Forecasting realized variance\n",
    "\n",
    "\n",
    "* The Rough Bergomi model\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "* Forecasting the forward variance curve\n",
    "\n",
    "\n",
    "* The time series of variance swaps\n",
    "\n",
    "\n",
    "* Relating historical and implied\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Motivation for econometric study\n",
    "\n",
    "- <span>[Al√≤s et al.]<sup id=\"cite_ref-Alos\" class=\"reference\"><a href=\"#cite_note-Alos\">[1]</a></sup>  and subsequently <span>[Fukasawa]<sup id=\"cite_ref-Fukasawa\" class=\"reference\"><a href=\"#cite_note-Fukasawa\">[9]</a></sup> showed that the empirically observed power-law term structure of the at-the-money volatility skew could be replicated in the short expiration limit by a stochastic volatility model where the volatility process is a function of fractional Brownian motion (fBm). \n",
    "\n",
    "\n",
    "- For such a model to offer a realistic description of the historical time series of instantaneous volatility, this time series would have to exhibit scaling properties consistent with fBm. \n",
    "\n",
    "\n",
    "- It is therefore natural to investigate the scaling properties of volatility time series.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The time series of realized variance\n",
    "\n",
    "- We would like to study the time series of instantaneous variance $v_t$ but of course cannot because $v_t$ is latent.\n",
    "\n",
    "\n",
    "- On the other hand, integrated variance $\\frac 1 \\delta \\,\\int_t^{t+\\delta}\\,v_s\\,ds$ may (in principle) be estimated arbitrarily accurately given enough price data.\n",
    "\n",
    "    - In practice, market microstructure noise makes estimation harder at very high frequency.\n",
    "    - Sophisticated estimators of integrated variance have been developed to adjust for market microstructure noise.  See Gatheral and Oomen<sup id=\"cite_ref-GO\" class=\"reference\"><a href=\"#cite_note-GO\"><span>[</span>11<span>]</span></a></sup> (for example) for details of these."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The Oxford-Man Institute of Quantitative Finance makes historical realized variance (RV) estimates freely available at http://realized.oxford-man.ox.ac.uk.  These estimates are updated daily.\n",
    "\n",
    "    - Each day, for 31 different indices, all trades and quotes are used to estimate realized (or integrated) variance over the trading day from open to close.\n",
    "\n",
    "\n",
    "\n",
    "- Using daily RV estimates as proxies for instantaneous variance, we may investigate the time series properties of integrated variance empirically."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "First update and save the latest Oxford-Man data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "download.file(url=\"https://realized.oxford-man.ox.ac.uk/images/oxfordmanrealizedvolatilityindices.zip\", destfile=\"oxfordRvData.zip\")\n",
    "unzip(zipfile=\"oxfordRvData.zip\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "There are many different estimates of realized variance, all of them very similar.  We will use the realized kernel estimates denoted by \".rk\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading required package: xts\n",
      "Loading required package: zoo\n",
      "\n",
      "Attaching package: 'zoo'\n",
      "\n",
      "The following objects are masked from 'package:base':\n",
      "\n",
      "    as.Date, as.Date.numeric\n",
      "\n",
      "Loading required package: TTR\n",
      "Version 0.4-0 included new data defaults. See ?getSymbols.\n"
     ]
    }
   ],
   "source": [
    "library(quantmod)\n",
    "library(repr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rv.data <- read.csv(\"OxfordManRealizedVolatilityIndices.csv\")\n",
    "\n",
    "rv1 <- data.frame(rv.data$X,rv.data$Symbol,rv.data$rk_th2) # Tukey-Hanning kernel\n",
    "names(rv1) <- c(\"Date\",\"Symbol\",\"rk\")\n",
    "index.names <- as.matrix(unique(rv1$Symbol))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rv.list <- NULL\n",
    "index.names <- as.matrix(index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n <- length(index.names)\n",
    "\n",
    "for (i in 1:n){\n",
    "    pick <- (rv1$Symbol==index.names[i])\n",
    "    tmp <- rv1[pick,]\n",
    "    dates <- strptime(tmp$Date,\"%Y-%m-%d\")\n",
    "    tmp.krv1 <- xts(tmp$rk,order.by=dates) \n",
    "    rv.list[[i]] <- tmp.krv1[(tmp.krv1!=\"\")&(tmp.krv1!=\"0\")]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>'.AEX'</li>\n",
       "\t<li>'.AORD'</li>\n",
       "\t<li>'.BFX'</li>\n",
       "\t<li>'.BSESN'</li>\n",
       "\t<li>'.BVLG'</li>\n",
       "\t<li>'.BVSP'</li>\n",
       "\t<li>'.DJI'</li>\n",
       "\t<li>'.FCHI'</li>\n",
       "\t<li>'.FTMIB'</li>\n",
       "\t<li>'.FTSE'</li>\n",
       "\t<li>'.GDAXI'</li>\n",
       "\t<li>'.GSPTSE'</li>\n",
       "\t<li>'.HSI'</li>\n",
       "\t<li>'.IBEX'</li>\n",
       "\t<li>'.IXIC'</li>\n",
       "\t<li>'.KS11'</li>\n",
       "\t<li>'.KSE'</li>\n",
       "\t<li>'.MXX'</li>\n",
       "\t<li>'.N225'</li>\n",
       "\t<li>'.NSEI'</li>\n",
       "\t<li>'.OMXC20'</li>\n",
       "\t<li>'.OMXHPI'</li>\n",
       "\t<li>'.OMXSPI'</li>\n",
       "\t<li>'.OSEAX'</li>\n",
       "\t<li>'.RUT'</li>\n",
       "\t<li>'.SMSI'</li>\n",
       "\t<li>'.SPX'</li>\n",
       "\t<li>'.SSEC'</li>\n",
       "\t<li>'.SSMI'</li>\n",
       "\t<li>'.STI'</li>\n",
       "\t<li>'.STOXX50E'</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item '.AEX'\n",
       "\\item '.AORD'\n",
       "\\item '.BFX'\n",
       "\\item '.BSESN'\n",
       "\\item '.BVLG'\n",
       "\\item '.BVSP'\n",
       "\\item '.DJI'\n",
       "\\item '.FCHI'\n",
       "\\item '.FTMIB'\n",
       "\\item '.FTSE'\n",
       "\\item '.GDAXI'\n",
       "\\item '.GSPTSE'\n",
       "\\item '.HSI'\n",
       "\\item '.IBEX'\n",
       "\\item '.IXIC'\n",
       "\\item '.KS11'\n",
       "\\item '.KSE'\n",
       "\\item '.MXX'\n",
       "\\item '.N225'\n",
       "\\item '.NSEI'\n",
       "\\item '.OMXC20'\n",
       "\\item '.OMXHPI'\n",
       "\\item '.OMXSPI'\n",
       "\\item '.OSEAX'\n",
       "\\item '.RUT'\n",
       "\\item '.SMSI'\n",
       "\\item '.SPX'\n",
       "\\item '.SSEC'\n",
       "\\item '.SSMI'\n",
       "\\item '.STI'\n",
       "\\item '.STOXX50E'\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. '.AEX'\n",
       "2. '.AORD'\n",
       "3. '.BFX'\n",
       "4. '.BSESN'\n",
       "5. '.BVLG'\n",
       "6. '.BVSP'\n",
       "7. '.DJI'\n",
       "8. '.FCHI'\n",
       "9. '.FTMIB'\n",
       "10. '.FTSE'\n",
       "11. '.GDAXI'\n",
       "12. '.GSPTSE'\n",
       "13. '.HSI'\n",
       "14. '.IBEX'\n",
       "15. '.IXIC'\n",
       "16. '.KS11'\n",
       "17. '.KSE'\n",
       "18. '.MXX'\n",
       "19. '.N225'\n",
       "20. '.NSEI'\n",
       "21. '.OMXC20'\n",
       "22. '.OMXHPI'\n",
       "23. '.OMXSPI'\n",
       "24. '.OSEAX'\n",
       "25. '.RUT'\n",
       "26. '.SMSI'\n",
       "27. '.SPX'\n",
       "28. '.SSEC'\n",
       "29. '.SSMI'\n",
       "30. '.STI'\n",
       "31. '.STOXX50E'\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       " [1] \".AEX\"      \".AORD\"     \".BFX\"      \".BSESN\"    \".BVLG\"     \".BVSP\"    \n",
       " [7] \".DJI\"      \".FCHI\"     \".FTMIB\"    \".FTSE\"     \".GDAXI\"    \".GSPTSE\"  \n",
       "[13] \".HSI\"      \".IBEX\"     \".IXIC\"     \".KS11\"     \".KSE\"      \".MXX\"     \n",
       "[19] \".N225\"     \".NSEI\"     \".OMXC20\"   \".OMXHPI\"   \".OMXSPI\"   \".OSEAX\"   \n",
       "[25] \".RUT\"      \".SMSI\"     \".SPX\"      \".SSEC\"     \".SSMI\"     \".STI\"     \n",
       "[31] \".STOXX50E\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "names(rv.list) <- index.names\n",
    "names(rv.list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let's plot SPX realized variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "library(repr)\n",
    "options(repr.plot.width=14,repr.plot.height=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "spx.rk <- rv.list[[\".SPX\"]]\n",
    "stoxx.rk <- rv.list[[\".STOXX50E\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(log(spx.rk), main=\"Log of SPX realized variance\",col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 1: Oxford-Man Log KRV estimates of SPX realized variance from January 2000 to the current date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print(head(spx.rk))\n",
    "print(tail(spx.rk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scaling of the volatility process\n",
    "\n",
    "\n",
    "For $q\\geq 0$, we define the $q$th sample moment of differences of log-volatility at a given lag $\\Delta$.($\\angl{\\cdot}$ denotes the sample average):\n",
    "\n",
    "$$\n",
    "m(q,\\Delta)=\\angl{\\left|\\log \\sigma_{t+\\Delta} -\\log \\sigma_{t} \\right|^q}\n",
    "$$\n",
    "\n",
    "For example\n",
    "\n",
    "$$\n",
    "m(2,\\Delta)=\\angl{\\left(\\log \\sigma_{t+\\Delta} -\\log \\sigma_{t} \\right)^2}\n",
    "$$\n",
    "\n",
    "is just the sample variance of differences in log-volatility at the lag $\\Delta$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scaling of $m(q,\\Delta)$ with lag $\\Delta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "sig <- sqrt(as.numeric(spx.rk))\n",
    "\n",
    "mq.del.Raw <- function(q,lag){mean(abs(diff(log(sig),lag=lag))^q)}\n",
    "mq.del <- function(x,q){sapply(x,function(x){mq.del.Raw(q,x)})}\n",
    "\n",
    "# Plot mq.del(1:100,q) for various q\n",
    "\n",
    "x <- 1:100\n",
    "\n",
    "mycol <- rainbow(5)\n",
    "\n",
    "ylab <- expression(paste(log,\" \",m(q,Delta)))\n",
    "xlab <- expression(paste(log, \" \", Delta))\n",
    "\n",
    "qVec <- c(.5,1,1.5,2,3)\n",
    "zeta.q <- numeric(5)\n",
    "q <- qVec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height=7, repr.plot.width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(log(x),log(mq.del(x,q)),pch=20,cex=.5,\n",
    "         ylab=ylab, xlab=xlab,ylim=c(-3,-.5))\n",
    "fit.lm <- lm(log(mq.del(x,q)) ~ log(x))\n",
    "abline(fit.lm, col=mycol[1],lwd=2)\n",
    "zeta.q[1] <- coef(fit.lm)[2]\n",
    "\n",
    "for (i in 2:5){\n",
    "    q <- qVec[i]\n",
    "    points(log(x),log(mq.del(x,q)),pch=20,cex=.5)\n",
    "    fit.lm <- lm(log(mq.del(x,q)) ~ log(x))\n",
    "    abline(fit.lm, col=mycol[i],lwd=2)\n",
    "    zeta.q[i] <- coef(fit.lm)[2]\n",
    "    }\n",
    " legend(\"bottomright\", c(\"q = 0.5\",\"q = 1.0\",\"q = 1.5\",\"q = 2.0\",\"q = 3.0\"),inset=0.05, lty=1, col = mycol)\n",
    "\n",
    "print(zeta.q)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 2: $\\log m(q,\\Delta)$ as a function of $\\log \\Delta$, SPX."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Monofractal scaling result\n",
    "\n",
    "- From the above log-log plot, we see that for each $q$, $m(q,\\Delta) \\propto \\Delta ^{\\zeta_q}$.\n",
    "\n",
    "\n",
    "- How does $\\zeta_q$ scale with $q$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scaling of $\\zeta_q$ with $q$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot(qVec,zeta.q,xlab=\"q\",ylab=expression(zeta[q]),pch=20,col=\"blue\",cex=2)\n",
    "fit.lm <- lm(zeta.q[1:4] ~ qVec[1:4]+0)\n",
    "abline(fit.lm, col=\"red\",lwd=2)\n",
    "(h.est <- coef(fit.lm)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 3: Scaling of $\\zeta_q$ with $q$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We find the monofractal scaling relationship\n",
    "\n",
    "$$\n",
    "\\zeta_q = q\\,H\n",
    "$$\n",
    "\n",
    "with $H \\approx 0.15$.\n",
    "\n",
    "- Note however that $H$ does vary over time, in a narrow range, as we will see later.\n",
    "\n",
    "\n",
    "- Note also that our estimate of $H$ is biased high because we proxied instantaneous variance $v_t$ with its average over each day $\\frac 1T\\,\\int_0^T\\,v_t\\,dt$, where $T$ is one trading day.\n",
    "    - On the other hand, the time series of realized variance is noisy and this causes our estimate of $H$ to be biased low.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- This scaling property as $\\Delta \\to 0$ is equivalent to $H$-H√∂lder continuity of paths of the volatility.\n",
    "    - Since $H \\ll 1/2$, *volatility is rough*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Estimated $H$ for all indices\n",
    "\n",
    "We now repeat this analysis for all 31 indices in the Oxford-Man dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "n <- length(rv.list)\n",
    "h <- numeric(n) # H is estimated as half of the slope\n",
    "nu <- numeric(n)\n",
    "\n",
    "for (i in 1:n){ # Run all the regressions\n",
    "  v <- rv.list[[i]]\n",
    "  sig <- sqrt(abs(as.numeric(v)))\n",
    "    \n",
    "  x <- 1:100\n",
    "  dlsig2 <- function(lag){mean((diff(log(sig),lag=lag))^2)}\n",
    "  dlsig2Vec <- function(x){sapply(x,dlsig2)}\n",
    "\n",
    "  fit.lm <- lm(log(dlsig2Vec(x)) ~ log(x))\n",
    "\n",
    "  nu[i] <- sqrt(exp(coef(fit.lm)[1]))\n",
    "  h[i] <- coef(fit.lm)[2]/2\n",
    "  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "(OxfordH <- data.frame(names(rv.list),h.est=h,nu.est=nu))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Distributions of $(\\log \\sigma_{t+\\Delta}-\\log \\sigma_t)$ for various lags $\\Delta$\n",
    "\n",
    "Having established these beautiful scaling results for the moments, how do the histograms look?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plotScaling <- function(j,scaleFactor){\n",
    "  v <- as.numeric(rv.list[[j]])\n",
    "  x <- 1:100\n",
    "  \n",
    "  xDel <- function(x,lag){diff(x,lag=lag)}\n",
    "  sd1 <- sd(xDel(log(v),1))\n",
    "  sdl <- function(lag){sd(xDel(log(v),lag))}\n",
    "\n",
    "  h <- OxfordH$h.est[j]\n",
    "  \n",
    "  plotLag <- function(lag){\n",
    "    y <- xDel(log(v),lag)\n",
    "    hist(y,breaks=100,freq=F,main=paste(\"Lag =\",lag,\"Days\"),xlab=NA)# Very long tailed!\n",
    "    curve(dnorm(x,mean=mean(y),sd=sd(y)),add=T,col=\"red\",lwd=2)\n",
    "    curve(dnorm(x,mean=0,sd=sd1*lag^h),add=T,lty=2,lwd=2,col=\"blue\")\n",
    "  }\n",
    "  \n",
    "  (lags <- scaleFactor^(0:3))\n",
    "  print(names(rv.list)[j])\n",
    "  par(mfrow=c(2,2))\n",
    "  par(mar=c(3,2,1,3))\n",
    "  for (i in 1:4){plotLag(lags[i])}\n",
    "  par(mfrow=c(1,1))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.height=5, repr.plot.width=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plotScaling(27,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 4: Histograms of $(\\log \\sigma_{t+\\Delta}-\\log \\sigma_t)$ for various lags $\\Delta$; normal fit in red; $\\Delta=1$ normal fit scaled by $\\Delta^{H}$ in blue.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Universality?\n",
    "\n",
    "- <span>[Gatheral, Jaisson and Rosenbaum]<sup id=\"cite_ref-GJR\" class=\"reference\"><a href=\"#cite_note-GJR\"><span>[</span>10<span>]</span></a></sup> compute daily realized variance estimates over one hour windows for DAX and Bund futures contracts, finding similar scaling relationships.\n",
    "\n",
    "\n",
    "- We have also checked that Gold and Crude Oil futures scale similarly.\n",
    "\n",
    "    - Although the increments $(\\log \\sigma_{t+\\Delta}-\\log \\sigma_t)$ seem to be fatter tailed than Gaussian.  \n",
    "    \n",
    "    \n",
    "- <span>[Bennedsen et al.]<sup id=\"cite_ref-HCE\" class=\"reference\"><a href=\"#cite_note-HCE\"><span>[</span>6<span>]</span></a></sup>, estimate volatility time series for more than five thousand individual US equities, finding rough volatility in every case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A microstructural explanation: A Hawkes model of price formation\n",
    "\n",
    "- Why might rough volatility be universal?\n",
    "\n",
    "\n",
    "\n",
    "- <span>[Jaisson and Rosenbaum]<sup id=\"cite_ref-JaissonRosenbaum\" class=\"reference\"><a href=\"#cite_note-JaissonRosenbaum\"><span>[</span>13<span>]</span></a></sup> show that rough volatility can be obtained as a scaling limit of a simple model of price dynamics in terms of Hawkes processes.\n",
    "\n",
    "\n",
    "- Remarkably, <span>[El Euch and Rosenbaum]<sup id=\"cite_ref-ElEuchRosenbaum\" class=\"reference\"><a href=\"#cite_note-ElEuchRosenbaum\"><span>[</span>7<span>]</span></a></sup> were able to compute the characteristic function of the resulting *rough Heston* model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A natural model of realized volatility\n",
    "\n",
    "- Distributions of differences in the log of realized variance are close to Gaussian.\n",
    "\n",
    "    - This motivates us to model $\\sigma_t=\\log v_t$ as a lognormal random variable.\n",
    "\n",
    "\n",
    "- Moreover, the scaling property of variance of RV differences suggests the model:\n",
    "<p>\n",
    "<a name=\"eq:dataDriven\"></a>(1)\n",
    "$$\n",
    "\\log \\sigma_{t+\\Delta} - \\log \\sigma_t =\\nu\\,\\left( W^H_{t+\\Delta}-W^H_t\\right)\n",
    "$$\n",
    "<p>\n",
    "where $W^H$ is fractional Brownian motion.\n",
    "\n",
    "\n",
    "- Indeed, if $H$ is constant, [(1)](#eq:dataDriven) is the *unique* model consistent with Gaussianity of log differences, the observed scaling, and continuity of the volatility process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fractional Brownian motion (fBm)\n",
    "\n",
    "- *Fractional Brownian motion* (fBm) $\\{W^H_t; t \\in \\mathbb{R}\\}$ is the unique Gaussian process with mean zero and autocovariance function\n",
    "$$\n",
    "\\ee{ W^H_t\\,W^H_s  } = \\frac12\\,\\left\\{ |t|^{2\\,H}+|s|^{2\\,H}-|t-s|^{2\\,H}  \\right\\}\n",
    "$$\n",
    "where $H \\in (0,1)$ is called the *Hurst index* or parameter.\n",
    "   - In particular, when $H=1/2$, fBm is just Brownian motion.\n",
    " \n",
    "   - If $H>1/2$, increments are positively correlated (\"trending\").\n",
    "   - If $H<1/2$, increments are negatively correlated (\"reverting\").\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Representations of fBm\n",
    "\n",
    "There are infinitely many possible representations of fBm in terms of Brownian motion.  For example, with $\\gamma = \\frac 12 - H$,\n",
    "\n",
    "\n",
    "<blockquote><div style=\"background-color:#add8e6; color:#FFFFFF; font-style: normal;  \" ><h4>\n",
    "Mandelbrot-Van Ness</h4>\n",
    "</div>\n",
    "<div style=\"background-color:#E8E8E8; color:#000000; font-style: normal; \">\n",
    "<br>\n",
    "\n",
    "$$\n",
    "W^H_t ={C_H}\\,\\left\\{\\int_{-\\infty}^t \\,\\frac{dW_s}{(t-s)^\\gamma} - \\int_{-\\infty}^0 \\,\\frac{dW_s}{(-s)^\\gamma}\\right\\}.\n",
    "$$\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "where the choice\n",
    "\n",
    "$$\n",
    "C_H = \\sqrt{ \\frac{2\\,H\\,\\Gamma(3/2-H)}{\\Gamma(H+1/2)\\,\\Gamma(2-2\\,H)}}\n",
    "$$\n",
    "\n",
    "ensures that\n",
    "\n",
    "$$\n",
    "\\ee{W^H_t\\,W^H_s }= \\frac{1}{2}\\,\\left\\{t^{2 H} + s^{2 H} - |t-s|^{2 H}\\right\\}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Efficient estimation of $H$\n",
    "\n",
    "- So far, we just used simple regression to estimate $H$.\n",
    "\n",
    "\n",
    "- When $H$ is small, as we find empirically, out of all the estimators that we tested, the ACF estimator adopted by <span>[Bennedsen et al.]<sup id=\"cite_ref-BLPdecoupling\" class=\"reference\"><a href=\"#cite_note-BLPdecoupling\"><span>[4]</span></a></sup> is the most efficient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heuristic derivation of the ACF estimator\n",
    "\n",
    "\n",
    "Once again, the covariance structure of fBm is given by\n",
    "\n",
    "$$\n",
    "\\E\\left[W^H_t\\,W^H_s\\right]= \\frac{1}{2}\\,\\left\\{t^{2 H} + s^{2 H} - |t-s|^{2 H}\\right\\}.\n",
    "$$\n",
    "\n",
    "\n",
    "Up to a multiplicative factor, our model is \n",
    "\n",
    "$$\n",
    "y_t = \\log v_t = W^H_t.\n",
    "$$\n",
    "\n",
    "Then\n",
    "$\n",
    "\\var[y_t] = t^{2 H}.\n",
    "$\n",
    "and\n",
    "\n",
    "\n",
    "$$\n",
    "\\cov[y_t,y_{t+\\Delta}] =  \\frac{1}{2}\\,\\left\\{t^{2 H} + (t+\\Delta)^{2 H} - \\Delta^{2 H}\\right\\}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Dividing one by the other gives\n",
    "\n",
    "$$\n",
    "\\rho(\\Delta) = \\frac{1}{2}\\,\\left\\{1 + \\left(1+\\frac\\Delta t\\right)^{2 H} - \\left(\\frac\\Delta t\\right)^{2 H}\\right\\}\n",
    "%&=& 1- \\frac{1}{2}\\,\\left(\\frac\\Delta t\\right)^{2 H} + O(\n",
    "$$\n",
    "\n",
    "\n",
    "Thus, for $\\Delta/t$ sufficiently small,\n",
    "\n",
    "\n",
    "$$\n",
    "1-\\rho(\\Delta) =\\frac12 \\left(\\frac{\\Delta}{t}\\right)^{2 H} + O\\left(\\frac{\\Delta}t\\right).\n",
    "$$\n",
    "\n",
    "- Note in particular that we expect the ACF estimator to work best when $H \\ll \\frac{1}{2}$.  \n",
    "\n",
    "- Also, when $H=\\frac12$, we have \n",
    "$\n",
    "\\rho(\\Delta) = 1\n",
    "$\n",
    "as we would expect for Brownian motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The ACF estimator\n",
    "\n",
    "Taking logs of each side, we obtain\n",
    "\n",
    "$$\n",
    "\\log(1- \\rho(\\Delta)) = a + 2\\,H\\, \\log \\Delta.\n",
    "$$\n",
    "\n",
    "- Thus $H$ can be estimated efficiently by regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h.acf <- function(path){\n",
    "    y.acf <- acf(path,plot=F)\n",
    "    log.del <- log(y.acf$lag[-1])\n",
    "    log.lhs <- log(1-y.acf$acf[-1])\n",
    "    fit.lm <- lm(log.lhs ~ log.del)\n",
    "    return(fit.lm$coef[2]/2)\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### An example: Estimate of $H$ for 2005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "yPath <- spx.rk[\"2005-01-01::2005-12-31\"]\n",
    "plot(yPath,col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 5: SPX realized kernel estimates of integrated variance for 2003."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h.acf(as.numeric(yPath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series of $H$ using ACF\n",
    "\n",
    "- We now draw the time series of $H$ using the ACF estimator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h.acf.i <- function(series)function(del)function(i){\n",
    "    rk.path <- as.numeric(series[(i-del):i])\n",
    "    h.acf(rk.path)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h.acf.i(spx.rk)(252)(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "h.acf.series <- function(series)function(del){\n",
    "    require(xts)\n",
    "    n <- length(series)\n",
    "    res <- sapply((1+del):n,h.acf.i(series)(del))\n",
    "    return(xts(res,order.by=index(series[(1+del):length(series)]),tzone = Sys.getenv(\"TZ\")))\n",
    "}\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Compare the two estimates of $H$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rownum <- which(OxfordH[,1]==\".SPX\")\n",
    "n.spx <- length(spx.rk)\n",
    "h.spx.acf <- as.numeric(h.acf.series(spx.rk)(n.spx-1))\n",
    "h.spx.regression <- OxfordH$h.est[rownum]\n",
    "nu.spx.regression <- OxfordH$nu.est[rownum]\n",
    "data.frame(h.spx.acf,h.spx.regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Looking again at the log-log plots of $m_q(\\Delta)$ against $\\Delta$, we note that the points don't quite lie on a straight line.\n",
    "\n",
    "\n",
    "- A more careful analysis that takes account of the bias due to averaging and the noisiness of the time series of realized variance gives us an estimate of $H$ more consistent with the ACF estimate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series of $H$ for SPX\n",
    "\n",
    "- Here $\\alpha=H-\\frac 12$.  Estimates use 15-minute data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2018/11/alpha_inTime.png\" align = \"left\" width=1000></h3> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 6:  Time series of H from <span>[Bennedsen et al.]<sup id=\"cite_ref-BLPdecoupling\" class=\"reference\"><a href=\"#cite_note-BLPdecoupling\"><span>[</span>4<span>]</span></a></sup>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Observations\n",
    "\n",
    "- $H$ tends to spike when the market is under stress.\n",
    "    - And seems close to zero when the market is calm.\n",
    "    - Could $H$ be related to underlying market liquidity?\n",
    "\n",
    "\n",
    "- Note the following peaks\n",
    "    - The Greek debt crisis in late 2011.\n",
    "    - The Brexit vote in 2015.  In this case $H$ rises with uncertainty then collapses.\n",
    " \n",
    " \n",
    " \n",
    "- When the market crashes, $H$ rises.\n",
    "    But often $H$ rises without the market crashing.\n",
    " \n",
    " \n",
    "- In particular, $H$ of the volatility time series seems to be a meaningful and relevant statistic.\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Repeat using the ACF estimator on daily realized kernel estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "h.spx.252 <-  h.acf.series(spx.rk)(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "options(repr.plot.width=14,repr.plot.height=7)\n",
    "plot(h.spx.252,main=\"SPX\",ylab=\"H\",col=\"red\")\n",
    "abline(h=median(h.spx.252),lty=2,col=\"red\",lwd=2)\n",
    "abline(h=mean(h.spx.252),lty=2,col=\"blue\",lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 7: Time series of $H$ using data realized kernel estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Time series of $H$ for STOXX50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h.stoxx.252 <- h.acf.series(stoxx.rk)(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(h.stoxx.252,main=\"STOXX50\",ylab=\"H\",col=\"blue\")\n",
    "abline(h=median(h.stoxx.252),lty=2,col=\"red\")\n",
    "abline(h=mean(h.stoxx.252),lty=2,col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 8: Time series of $H$ for STOXX50 using data realized kernel estimates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot both together "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot(cbind(h.spx.252,h.stoxx.252),main=\"SPX plus STOXX50\",col=c(\"red\",\"blue\"),lwd=2,major.ticks= \"years\",\n",
    "        minor.ticks = FALSE)\n",
    "legend((x=\"topleft\"), legend = c(\"SPY\", \"STOXX50\"),lty = 1,lwd=2,col = c(\"red\",\"blue\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Figure 9: Sometimes the peaks line up, and sometimes not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Line up time series of $H$ with VIX\n",
    "\n",
    "- First we use `quantmod` to download VIX data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "options(\"getSymbols.warning4.0\"=FALSE,\"getSymbols.yahoo.warning\"=FALSE)\n",
    "getSymbols('^VIX',from=\"2001-01-01\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Superimpose VIX and H time series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot(as.zoo(Cl(VIX)),col=\"blue\",yaxt=\"n\",ylab=\"\",xlab=\"Date\")\n",
    "par(new=TRUE)               \n",
    "plot(as.zoo(h.spx.252),col=\"red\", xaxt=\"n\", yaxt=\"n\",  xlab=\"\", ylab=\"\",lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 10: VIX in blue; H in red.  Sometimes $H$ increases with VIX and sometimes not."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comte and Renault: FSV model\n",
    "\n",
    "<span>[Comte and Renault]<sup id=\"cite_ref-ComteRenault\" class=\"reference\"><a href=\"#cite_note-ComteRenault\"><span>[</span>7<span>]</span></a></sup> were perhaps the first to model volatility using fractional Brownian motion.  \n",
    "\n",
    "In their fractional stochastic volatility (FSV) model,\n",
    "\n",
    "$$\n",
    "\\bea\n",
    "\\frac{dS_t}{S_t} &=& \\sigma_t\\,dZ_t\\nonumber\\\\\n",
    "d\\log \\sigma_t &=& -\\alpha\\,(\\log \\sigma_t - \\theta)\\,dt+ \\gamma\\,d\\hat W^H_t\n",
    "%\\label{eq:FSV}\n",
    "\\eea\n",
    "$$\n",
    "\n",
    "with\n",
    "\n",
    "$$\n",
    "\\hat W^H_t = \\int_0^t\\,\\frac{(t-s)^{H-1/2}}{\\Gamma(H+1/2)}\\,dW_s,\\quad 1/2 \\leq H < 1\n",
    "$$\n",
    "\n",
    "and $\\ee{dW_t\\,dZ_t}=\\rho\\,dt$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RFSV and FSV\n",
    "\n",
    " \n",
    "  - The model [(1)](#eq:dataDriven):\n",
    "$$\n",
    "\\log \\sigma_{t+\\Delta} - \\log \\sigma_t =\\nu\\,\\left( W^H_{t+\\Delta}-W^H_t\\right)\n",
    "$$\n",
    "is not stationary.\n",
    "     - Stationarity is desirable both for mathematical tractability and also to ensure reasonableness of the model at very large times. \n",
    "  \n",
    "  \n",
    "- The RFSV model (the stationary version of [(1)](#eq:dataDriven)) is formally identical to the FSV model.  Except that\n",
    " \n",
    "  - $H<1/2$ in RFSV vs $H>1/2$ in FSV.\n",
    "  - $\\alpha\\,T \\gg1$  in RFSV vs $\\alpha\\,T \\sim 1$ in FSV,\n",
    "  where $T$ is a typical timescale of interest.\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### FSV and long memory\n",
    "\n",
    " \n",
    "- Why did <span>[Comte and Renault]<sup id=\"cite_ref-ComteRenault\" class=\"reference\"><a href=\"#cite_note-ComteRenault\"><span>[</span>6<span>]</span></a></sup> choose $H>1/2$?\n",
    " \n",
    "  - Because it has been a widely-accepted stylized fact that the volatility time series exhibits long memory.  \n",
    "\n",
    "\n",
    "- In this technical sense, *long memory* means that the autocorrelation function of volatility decays as a power-law.\n",
    "\n",
    "\n",
    "- One of the influential papers that established this was  <span>[Andersen, Bollerslev, Diebold and Ebens]<sup id=\"cite_ref-ABDE\" class=\"reference\"><a href=\"#cite_note-ABDE\"><span>[2]</span></a></sup> which estimated the degree $d$ of fractional integration from daily realized variance data for the 30 DJIA stocks.  They effectively tried to fit something like FIGARCH.\n",
    " \n",
    "  - Using the GPH (Geweke-Porter-Hudak) estimator, they found $d$ around $0.35$ which implies that the ACF $\\rho(\\tau)  \\sim \\tau^{2\\,d-1} = \\tau ^{-0.3}$ as $\\tau \\to \\infty$.\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log-log plot of empirical autocorrelation of volatility (correlogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "v <- as.numeric(rv.list[[\".SPX\"]]  )\n",
    "ac.sig <- acf(sqrt(v),lag=100,plot=F)\n",
    "plot(log(ac.sig$lag[-1]),log(ac.sig$acf[-1]),pch=20,\n",
    "     ylab=expression(rho[sigma](Delta)),xlab=expression(paste(Delta,\" (days)\")),col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 5: A correlogram of $\\sigma_t=\\sqrt{RV_t}$; it doesn't look linear!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Power-law fit\n",
    "\n",
    "- We exclude the first 20 points so as to fit the tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "(fit.lm <- lm(log(ac.sig$acf[-1][-(1:20)]) ~ log(ac.sig$lag[-1][-(1:20)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(log(ac.sig$lag[-1]),log(ac.sig$acf[-1]),pch=20,\n",
    "     ylab=expression(rho(Delta)),xlab=expression(paste(Delta,\" (days)\")),col=\"blue\")\n",
    "abline(fit.lm,col=\"red\",lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 6: Correlogram of $\\sigma_t=\\sqrt{RV_t}$ with power-law fit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In other words, just fitting a straight line to the log-log plot of the autocorrelation $\\rho_\\sigma(\\Delta)$ of the volatility we get\n",
    "<p>\n",
    "$$\n",
    "\\rho_\\sigma(\\Delta) \\sim \\Delta^{-0.4}\n",
    "$$\n",
    "as $\\Delta \\to \\infty$.\n",
    "\n",
    "\n",
    "- This corresponds to $d=0.3$, consistent with the $d=0.35$ found by <span>[Andersen, Bollerslev, Diebold and Ebens]<sup id=\"cite_ref-ABDE\" class=\"reference\"><a href=\"#cite_note-ABDE\"><span>[</span>1<span>]</span></a></sup>.\n",
    "\n",
    "\n",
    "- Note however that the correlogram does not look like a straight line on the log-log plot!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Heuristic derivation of autocorrelation function of log volatility\n",
    "\n",
    "- In the RFSV model, it makes sense to compute the correlogram of log-volatility rather than volatility.\n",
    "\n",
    "- We have $\\log \\sigma_t = \\nu\\,W^H_t + \\text{const.}$.  Then\n",
    "<p>\n",
    "$$\n",
    "\\cov\\left[\\log \\sigma_t,\\log \\sigma_{t+\\Delta}\\right]\n",
    "=\\frac{\\nu^2}{2}\\,\\left\\{   t^{2 H} + (t+\\Delta)^{2 H} - \\Delta ^{2 H}\\right\\}\\\\\n",
    "$$\n",
    "Similarly,\n",
    "$$\n",
    "\\var\\left[\\log \\sigma_t\\right] = \\nu^2\\,t^{2\\,H}.\n",
    "$$\n",
    "\n",
    "- Thus\n",
    "$$\n",
    "\\rho(\\Delta)=\\frac{\\cov\\left[\\log \\sigma_t,\\log \\sigma_{t+\\Delta}\\right]}{\\sqrt{\\var\\left[\\log \\sigma_t\\right] \\,\\var\\left[\\log \\sigma_{t+\\Delta}\\right] }} \n",
    "=\\frac12\\,\\left\\{\\left(1+\\frac t \\Delta\\right)^{-H} + \\left(1+\\frac t \\Delta\\right)^{H} - \\left(\\frac t \\Delta\\right)^{2 H}\\, \\left(1+\\frac t \\Delta\\right)^{-H} \\right\\}\n",
    ".\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Implement the formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rhoFormula <- function(delta,t,H){\n",
    "    delt <- delta/t\n",
    "    res <- 1/2*((1+delt)^(-H)+ (1+delt)^(H)  - delt^(2*H)*(1+delt)^(-H))\n",
    "    return(res)\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Log-log plot of empirical autocorrelation of log volatility (correlogram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "v <- rv.list[[\".SPX\"]]  \n",
    "sig <- sqrt(as.numeric(v))\n",
    "aclog <-acf(log(sig),lag=100,plot=F)\n",
    "plot(aclog$lag[-1],aclog$acf[-1],pch=20,ylab=expression(rho(Delta)),\n",
    "     xlab=expression(paste(Delta,\" (days)\")),log=\"xy\",col=\"blue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Fit the RFSV autocorrelation formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "obj.acf <- function(paramvec){\n",
    "    t <- paramvec[1]\n",
    "    H <- paramvec[2]\n",
    "    delvec <- aclog$lag[-1]\n",
    "    rho.acf <- aclog$acf[-1]\n",
    "    rho.fit <- rhoFormula(delvec,t,H)\n",
    "    return(sum((rho.acf-rho.fit)^2)*1e6)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "optim(c(200,.1),obj.acf,method =\"L-BFGS-B\",lower=c(1,.0001),upper=c(100000,.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Correlogram with fitted formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(aclog$lag[-1],aclog$acf[-1],pch=20,ylab=expression(rho(Delta)),\n",
    "     xlab=expression(paste(Delta,\" (days)\")),log=\"xy\",col=\"blue\")\n",
    "curve(rhoFormula(x,29.54,.22),from=0.00001,to=100,add=T,col=\"red\",lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 7: Here we superimpose the RFSV functional form $\\rho(\\Delta) \\sim \\exp\\left\\{a+ b\\,\\Delta^{2\\,H}\\right\\}$ (in red) on the empirical curve (in blue).  The log-correlogram is not linear in the RFSV model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot vs $\\Delta^{2 H}$\n",
    "\n",
    "- Again, we have $\\log \\sigma_t = \\nu\\,W^H_t + \\text{const.}$ so\n",
    "<p>\n",
    "$$\n",
    "\\cov\\left[\\log \\sigma_t,\\log \\sigma_{t+\\Delta}\\right]\n",
    "=\\var\\left[\\log \\sigma_t\\right] -\\nu^2\\,t^{2\\,H} \\,\\Delta ^{2 H}.\n",
    "$$\n",
    "\n",
    "\n",
    "- Thus $\\cov\\left[\\log \\sigma_t,\\log \\sigma_{t+\\Delta}\\right]$ should be a linear function of $\\Delta ^{2 H}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "sig.cov <- acf(sig,lag.max=100,type=\"covariance\",plot=F)$acf[-1]\n",
    "x <- (1:100)^(2*h.spx.regression)\n",
    "plot(x,sig.cov,pch=20,col=\"dark green\",ylab= expression(paste(\"Covariance of log \",sigma)),xlab=expression(Delta^0.30 ))\n",
    "abline(lm(sig.cov~x),col=\"red\",lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 8: The data is very consistent with the RFSV model.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Long memory of volatility may be spurious\n",
    "\n",
    " \n",
    "- Figures 5, 6, 7 and 8 all demonstrate consistency of the realized kernel data with RFSV and are inconsistent with power-law decay of the autocorrelation function.\n",
    "    - RFSV does not have this long memory property.\n",
    "\n",
    "\n",
    "- Moreover, <span>[Gatheral, Jaisson and Rosenbaum]<sup id=\"cite_ref-GJR\" class=\"reference\"><a href=\"#cite_note-GJR\"><span>[</span>6<span>]</span></a></sup> simulate volatility in the RFSV model and apply standard estimators to the simulated data.\n",
    "\n",
    "    - Real data and simulated data generate very similar plots and similar estimates of the long memory parameter to those found in the prior literature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "\n",
    "- Classical estimation procedures seem to identify spurious long memory of volatility.\n",
    "\n",
    "\n",
    "- Here is a quote from <span>[Bennedsen, Lunde and Pakkanen]<sup id=\"cite_ref-BLPdecoupling\" class=\"reference\"><a href=\"#cite_note-BLPdecoupling\"><span>[</span>4<span>]</span></a></sup>:\n",
    "\n",
    "> Having examined intraday volatility measurements on the E-mini S&P 500 futures contract, we can conclude that volatility is rough, highly persistent, and non-Gaussian. However, we were unable to distinguish between genuine long memory and persistence, yet technically short memory in the data.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Incompatibility of FSV with realized variance (RV) data\n",
    "\n",
    " \n",
    "  - In Figure 9, we demonstrate graphically that long memory volatility models such as FSV with $H>1/2$ are not compatible with the RV data.\n",
    "\n",
    "\n",
    "  - In the FSV model, the autocorrelation function $\\rho(\\Delta) \\propto \\Delta^{2\\,H-2}$.  Then, for long memory, we must have $1/2<H<1$.\n",
    "    - For $\\Delta \\gg 1/\\alpha$, stationarity kicks in and $m(2,\\Delta)$ tends to a constant as $\\Delta \\to \\infty$.\n",
    "    - For $\\Delta \\ll 1/\\alpha$, mean reversion is not significant and $m(2,\\Delta) \\propto \\Delta^{2\\,H}$.\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### RFSV vs FSV\n",
    "\n",
    "- We can compute $m(2,\\Delta)$ explicitly in both the FSV and RFSV models.\n",
    "\n",
    "\n",
    "- The smallest possible value of $H$ in FSV is $H=1/2$.  One empirical estimate in the literature says that $H \\approx 0.53$ some time in 2008.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Let's see how the theoretical estimates of $m(2,\\Delta)$ compare with data.\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2015/02/FsvVsRFSV.png\" align = \"left\" width=900></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 9: Black points are empirical estimates of $m(2,\\Delta)$; the blue line is the FSV model with $\\alpha=0.5$ and $H=0.53$; the orange line is the RFSV model with $\\alpha=0$ and $H=0.14$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Does simulated RSFV data look real?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2018/11/volRealFake.png\" align = \"left\" width=900></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 10: Volatility of SPX (above) and of the RFSV model (below)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remarks on the comparison\n",
    "\n",
    " \n",
    "  - In respect of roughness, the simulated and actual graphs look very alike. \n",
    " \n",
    "      - Persistent periods of high volatility alternate with low volatility periods. \n",
    "  \n",
    "  \n",
    "  - $H \\sim 0.1$ generates very rough looking sample paths (compared with $H=1/2$ for Brownian motion).\n",
    " \n",
    " \n",
    "  - Hence *rough volatility*.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "  - On closer inspection, we observe fractal-type behavior.\n",
    " \n",
    " \n",
    "  - The graph of volatility over a small time period looks like the same graph over a much longer time period.\n",
    " \n",
    " \n",
    "  - This feature of volatility has been investigated both empirically and theoretically in, for example, <span>[Bacry and Muzy]<sup id=\"cite_ref-BacryMuzy\" class=\"reference\"><a href=\"#cite_note-BacryMuzy\"><span>[3]</span></a></sup>\n",
    ".\n",
    "      - In particular, their Multifractal Random Walk (MRW) is related to a limiting case of the RSFV model as $H \\to 0$.\n",
    "  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Applications\n",
    "\n",
    "- What is this rough volatility model good for?\n",
    "\n",
    "\n",
    "- If we could change measure from $\\mP$ to $\\mQ$, we would be able to price options.  \n",
    "    - We will explore this in Lecture 2.\n",
    "    \n",
    "    \n",
    "- Another obvious application is to volatility forecasting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forcasting fBm\n",
    "\n",
    " \n",
    "- In the RFSV model [(1)](#eq:dataDriven), $\\log \\sigma_t \\approx \\nu\\,W^H_t+C$ for some constant $C$.\n",
    "\n",
    "\n",
    "-  <span>[Nuzman and Poor]<sup id=\"cite_ref-NuzmanPoor\" class=\"reference\"><a href=\"#cite_note-NuzmanPoor\"><span>[</span>14<span>]</span></a></sup> show that $W^H_{t+\\Delta}$ is conditionally Gaussian with conditional expectation\n",
    "<p>\n",
    "$$\\E[W^H_{t+\\Delta}|\\cF_t]=\\frac{\\cos(H\\pi)}{\\pi} \\Delta^{H+1/2} \\int_{-\\infty}^t \\frac{W^H_s}{(t-s+\\Delta)(t-s)^{H+1/2}} ds\n",
    "$$  \n",
    "and conditional variance\n",
    "<p>\n",
    "$$\n",
    "\\text{Var}[W^H_{t+\\Delta}|\\cF_t]=\\tilde c\\,\\Delta^{2H}.\n",
    "$$\n",
    "where $$\n",
    "\\tilde c = \\frac{\\Gamma(3/2-H)}{\\Gamma(H+1/2)\\,\\Gamma(2-2H)}.\n",
    "$$\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### A heuristic explanation of the formula\n",
    "\n",
    "\n",
    "- The forecast formula comes from regressing $W^H_{t+\\Delta}$ against the $W^H_s$ with $s<t$.\n",
    "\n",
    "\n",
    "- Let \n",
    "$$\n",
    "\\beta(u,\\Delta) = \\frac{\\cos(H\\pi)}{\\pi} \\Delta^{H+1/2}\\frac{1} {(u+\\Delta)\\,u^{H+1/2}} .\n",
    "$$\n",
    "Then, for $t,\\Delta>0$ and $0<H< \\frac12$,\n",
    "$$\n",
    "\\int_0^\\infty\\,\\beta(u,\\Delta)\\,|t-u|^{2 H} \\,du = (t+\\Delta)^{2 H}.\n",
    "$$\n",
    "    - In particular, \n",
    "$$\n",
    "\\int_0^\\infty\\,\\beta(u,\\Delta)\\,du=1.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "- With $\\beta(u,\\Delta) $ thus defined and for $s<t$,\n",
    "<p>\n",
    "$$\n",
    "\\ee{ W^H_s\\,\\left( W^H_{t+\\Delta} - \\int_{-\\infty}^t\\,\\beta(t-u,\\Delta)\\,W^H_u\\,du  \\right)  } = 0.\n",
    "$$\n",
    "<p>\n",
    "    - In other words, the $\\beta(t-u,\\Delta)$ are the normal regression coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The forecast formula\n",
    " \n",
    "Using that $W^H$ is a Gaussian random variable, we get that\n",
    "\n",
    "<blockquote><div style=\"background-color:#add8e6; color:#FFFFFF; font-style: normal;  \" ><h4>\n",
    "Variance forecast formula</h4>\n",
    "</div>\n",
    "<div style=\"background-color:#E8E8E8; color:#000000; font-style: normal; \">\n",
    "<br>\n",
    "\n",
    "<a name=\"eq:vForecast\"></a>(3)\n",
    "$$\n",
    "\\eefm{v_{t+\\Delta}}{\\mP}=\\exp\\left\\{\\eefm{\\log(v_{t+\\Delta})}{\\mP}+2\\, \\tilde c\\,\\nu^2\\Delta^{2\\,H}\\right\\}\n",
    "%\\label{eq:vForecast}\n",
    "$$\n",
    "\n",
    "<br>\n",
    "\n",
    "</div>\n",
    "\n",
    "</blockquote>\n",
    "\n",
    "where \n",
    "\n",
    "$$\n",
    "\\beas\n",
    "&&\\eefm{\\log v_{t+\\Delta}}{\\mP}\\\\\n",
    "&&= \\frac{\\cos(H\\pi)}{\\pi} \\Delta^{H+1/2} \\int_{-\\infty}^t \\frac{\\log v_s}{(t-s+\\Delta)(t-s)^{H+1/2}} ds.\n",
    "\\eeas\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Discretization of the forecast formula\n",
    "\n",
    "In <span>[Gatheral, Jaisson, Rosenbaum]<sup id=\"cite_ref-GJR\" class=\"reference\"><a href=\"#cite_note-GJR\"><span>[</span>4<span>]</span></a></sup>, we discretize the integral by taking mid-points as in \n",
    "\n",
    "$$\n",
    "\\eefm{\\log v_{t+\\Delta}}{\\mP}\n",
    "\\approx  \\frac 1A\\, \\sum_{j=0}^L\\,\\frac{\\log v_{t-j}}{\\left(j+\\frac12+ \\Delta\\right)\\,(j+\\frac 12)^{H+1/2}}.\n",
    "$$\n",
    "\n",
    "where $L$ is the maximum number of lags and the normalizing constant $A$ is given by\n",
    "\n",
    "$$\n",
    "A = \\sum_{j=0}^\\infty\\,\\frac{1}{\\left(j+\\frac12+ \\Delta\\right)\\,(j+\\frac 12)^{H+1/2}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Inspired by <span>[Bennedsen, Lunde and Pakkanen]<sup id=\"cite_ref-BLPdecoupling\" class=\"reference\"><a href=\"#cite_note-BLPdecoupling\"><span>[</span>4<span>]</span></a></sup>, we approximate the first term in the sum more accurately as follows.\n",
    "\n",
    "$$\n",
    "\\eefm{\\log v_{t+\\Delta}}{\\mP}\n",
    "\\approx  \\frac 1A\\, \\left\\{ \\frac{\\log v_t}{(s^\\star+ \\Delta)\\,(s^\\star)^{H+1/2}} + \n",
    "\\sum_{j=1}^L\\,\\frac{\\log v_{t-j}}{(j+\\frac12+ \\Delta)\\,(j+\\frac 12)^{H+1/2}}\\right\\}\n",
    "$$\n",
    "\n",
    "where $s^\\star$ is chosen such that\n",
    "\n",
    "$$\n",
    "\\frac{1}{\\gamma} = \\int_0^1\\,\\frac{ds}{s^{H+\\frac12}} = \\frac{1}{{s^\\star}^{H+\\frac12}} = \\frac{1}{{s^\\star}^{1-\\gamma}} \n",
    "$$\n",
    "\n",
    "where $\\gamma = \\frac12-H$.  Thus\n",
    "\n",
    "$$\n",
    "s^\\star = \\gamma^{\\frac{1}{1-\\gamma}}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Implement variance forecast in R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Find all of the dates\n",
    "dateIndex <- substr(as.character(index(spx.rk)),1,10) # Create index of dates\n",
    "\n",
    "cTilde <- function(h){gamma(3/2-h)/(gamma(h+1/2)*gamma(2-2*h))} # Factor because we are computing conditional on \\cF_t\n",
    "\n",
    "# XTS compatible version of forecast\n",
    "rv.forecast.XTS <- function(rvdata,h,date,nLags,delta,nu){\n",
    "    gam <- 1/2-h\n",
    "    j <- (1:nLags)-1\n",
    "    cf <- 1/((j+1/2)^(h+1/2)*(j+1/2+delta)) # Lowest number should apply to latest date\n",
    "    s.star <- gam^(1/(1-gam))\n",
    "    cf[1] <- 1/(s.star^(h+1/2)*(s.star+delta))\n",
    "    datepos <- which(dateIndex==date)\n",
    "    ldata <- log(as.numeric(rvdata[datepos-j])) # Note that this object is ordered from earlier to later\n",
    "    pick <- which(!is.na(ldata))\n",
    "    norm <- sum(cf[pick])\n",
    "    fcst <- cf[pick]%*%ldata[rev(pick)]/norm # Most recent dates get the highest weight\n",
    "    return(exp(fcst+2*nu^2*cTilde(h)*delta^(2*h)))\n",
    "\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SPX actual vs forecast variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- In order to forecast using (3), we need estimates of $H$ and $\\nu$.\n",
    "\n",
    "    - We use our estimates of $H$ and $\\nu$ from the regressions rather than from the ACF estimator.\n",
    "    - The choice does not seem to make much difference.\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "var.forecast.spx <- function(h,nu)function(del){\n",
    "    n <- length(spx.rk)\n",
    "    nLags <- 200\n",
    "    \n",
    "    range <- nLags:(n-del)\n",
    "    rv.predict <- sapply(dateIndex[range],function(d){rv.forecast.XTS(rvdata=spx.rk,h,d,nLags=nLags,delta=del,nu)})\n",
    "    rv.actual <- spx.rk[range+del]\n",
    "    return(list(rv.predict=rv.predict,rv.actual=rv.actual))\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- From experiment, we found that around 200 lags works best.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scatter plot of delta days ahead predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "del <- 1\n",
    "vf <- var.forecast.spx(h=h.spx.regression,nu=nu.spx.regression)(del)\n",
    "rv.predict <- vf$rv.predict\n",
    "rv.actual <- vf$rv.actual\n",
    "vol.predict <- sqrt(as.numeric(rv.predict))\n",
    "vol.actual <- sqrt(as.numeric(rv.actual))\n",
    "vol.actual <-  sqrt(as.numeric(rv.actual))                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "c(mean(vol.actual-vol.predict),sd(vol.actual-vol.predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(vol.predict,vol.actual,col=\"blue\",pch=20, ylab=\"Actual vol.\", xlab=\"Predicted vol.\")\n",
    "abline(coef=c(0,1),col=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 11: Actual vols vs predicted vols."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Which point is the outlier?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rv.actual[which(as.numeric(vol.actual)>.09)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "rv.predict[which(as.numeric(vol.predict)>.06)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Superimpose actual and predicted vols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "plot(vol.actual, col=\"blue\",type=\"l\")\n",
    "lines(vol.predict, col=\"red\",type=\"l\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 12: Actual volatilities in blue; predicted vols in red.  Note that volatilities are in daily terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### VolX\n",
    "\n",
    "- The commercial company VolX (http://volx.us) has developed a number of RealVol Instruments and RealVol Indices based on realized volatility as defined by the RealVol Formulas.\n",
    "    - Their business model is to license these indices to exchanges and information providers.\n",
    "\n",
    "\n",
    "- They publish daily forecasts of RV using HARK (which is HAR-RV with Kalman filtering, and RVOL, an implementation of the Rough Volatility forecast.\n",
    "\n",
    "\n",
    "- You can compare forecast versus actual volatility for the two estimators here: http://www.volx.us/volatilitycharts.shtml?2&SPY&PRED."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### VolX screenshots\n",
    "\n",
    "<h2><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2018/11/RVOL.png\" align = \"center\" width=750></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<h2><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2018/11/RVOLdist.png\" align = \"center\" width=750></h2>\n",
    "<h2><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2018/11/HVOLdist.png\" align = \"center\" width=750></h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conditional and unconditional variances\n",
    "\n",
    "- The HAR and rough volatility forecasts are both impressive.\n",
    "    - Much superior to alternatives such as GARCH.\n",
    "    \n",
    "- However, HAR is a regression and rough volatility is a proper model.\n",
    "\n",
    "\n",
    "- One practical consequence is that we can put error bars on our volatility forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### So how good is the forecast?\n",
    "\n",
    "Specifically, by how much is the variance of the future variance reduced by taking into account the whole history  of the fBm?\n",
    "- In practice of course, we only consider some finite history, 200 points say.\n",
    "\n",
    "- We know this again from <span>[Nuzman and Poor]<sup id=\"cite_ref-NuzmanPoor\" class=\"reference\"><a href=\"#cite_note-NuzmanPoor\"><span>[</span>10<span>]</span></a></sup> who showed that the ratio of the conditional to the unconditional variance of the $\\log v_t$ is\n",
    "\n",
    "$$\n",
    "\\tilde c = \\frac{\\Gamma(3/2-H)}{\\Gamma(H+1/2)\\,\\Gamma(2-2H)}.\n",
    "$$\n",
    "\n",
    "\n",
    "- We can compute this ratio empirically and compare with the model prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unconditional and conditional variance vs lag $\\Delta$\n",
    "\n",
    "First we compute the time series of prediction errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "log.vol.err <- function(del){\n",
    "    vf <- var.forecast.spx(h=h.spx.regression,nu=nu.spx.regression)(del)\n",
    "    rv.predict <- vf$rv.predict\n",
    "    rv.actual <- vf$rv.actual\n",
    "    vol.predict <- sqrt(as.numeric(rv.predict))\n",
    "    vol.actual <-  sqrt(as.numeric(rv.actual)) \n",
    "    err <- log(vol.actual)-log(vol.predict)\n",
    "    return(err)\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "var.log.err <- function(del){\n",
    "    var(log.vol.err(del))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "var.log.err(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "The following code takes too long to run.  You can run it by uncommenting the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "del <- 1:100\n",
    "#var.log.err.del <- sapply(del,var.log.err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#save(var.log.err.del ,file=\"varerr201811.rData\")\n",
    "load(file=\"varerr201811.rData\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Plot of conditional and unconditional variance\n",
    "\n",
    "- The unconditional variance of differences in log-vol is given by\n",
    "\n",
    "$$\n",
    "m(2,\\Delta)=\\angl{\\left(\\log \\sigma_{t+\\Delta} -\\log \\sigma_{t} \\right)^2}.\n",
    "$$\n",
    "\n",
    "- The conditional variance is given by `var.log.err`$(\\Delta)$.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(del,mq.del(del,2),pch=20,cex=1,ylab=expression(Variance), \n",
    "     xlab=expression(Delta),col=\"blue\",ylim=c(0,.35),\n",
    "     main= \"Unconditional and conditional variance\")\n",
    "curve(nu.spx.regression^2*x^(2*h.spx.regression),from=0,to=100,add=T,col=\"red\",lwd=2,n=1000)\n",
    "points(del,var.log.err.del,col=\"green4\",pch=20)\n",
    "curve(cTilde(h.spx.regression)* nu.spx.regression^2*x^(2*h.spx.regression),from=0,to=100,\n",
    "      add=T,col=\"orange\",lwd=2,n=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 13: Actual unconditional variance in blue, rough volatility prediction in red; Actual conditional variance in green, rough volatility prediction in orange."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Amazing agreement between data and model\n",
    "\n",
    "- We observe that the ratio of conditional to unconditional variance is more or less *exactly* as predicted by the model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pricing under rough volatility\n",
    "\n",
    "Following <span>[Bayer, Friz and Gatheral]<sup id=\"cite_ref-BFG\" class=\"reference\"><a href=\"#cite_note-BFG\"><span>[</span>4<span>]</span></a></sup>, the foregoing behavior suggest the following model for volatility under the real (or historical or physical) measure $\\mP$:\n",
    "\n",
    "$$\n",
    "\\log \\sigma_u - \\log \\sigma_t =\\nu\\,\\left(W^H_u-W^H_t\\right), \\quad u>t.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $\\gamma=\\frac{1}{2}-H$.  We choose the Mandelbrot-Van Ness representation of fractional Brownian motion $W^H$ as follows:\n",
    "\n",
    "$$\n",
    "W^H_t ={C_H}\\,\\left\\{\\int_{-\\infty}^t \\,\\frac{dW^{\\mP}_s}{(t-s)^\\gamma} - \\int_{-\\infty}^0 \\,\\frac{dW^{\\mP}_s}{(-s)^\\gamma}\\right\\}\n",
    "$$\n",
    "\n",
    "where the choice\n",
    "\n",
    "$$\n",
    "C_H = \\sqrt{ \\frac{2\\,H\\,\\Gamma(3/2-H)}{\\Gamma(H+1/2)\\,\\Gamma(2-2\\,H)}}\n",
    "$$\n",
    "\n",
    "ensures that\n",
    "$$\n",
    "\\E\\left[W^H_t\\,W^H_s\\right]= \\frac{1}{2}\\,\\left\\{t^{2 H} + s^{2 H} - |t-s|^{2 H}\\right\\}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Then\n",
    "\n",
    "$$\n",
    "\\beas\n",
    "&&\\log v_u - \\log v_t \\nonumber\\\\\n",
    "&=&2 \\,\\nu\\,C_H\\,\\left\\{ \\int_t^u\\,\\frac{1}{(u-s)^\\gamma}\\,d{W}^{\\mP}_s  \\\\+\\int_{-\\infty}^t\\,\\left[ \\frac{1}{(u-s)^\\gamma}-\\frac{1}{(t-s)^\\gamma} \\right]\\,d{W}^{\\mP}_s\\right\\}\\nonumber\\\\\n",
    "&=:& 2\\,\\nu\\,C_H\\,\\left[M_t(u)+ Z_t(u)\\right].\n",
    "\\eeas\n",
    "$$\n",
    "\n",
    "- Note that $\\eefm{M_t(u)}{\\mP}=0$ and $Z_t(u)$ is $\\cF_t$-measurable.  \n",
    "\n",
    "  - To price options, it would seem that we would need to know $\\cF_t$, the entire history of the Brownian motion $W_s$ for $s<t$!\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pricing under $\\mP$\n",
    "\n",
    "\n",
    "Let\n",
    "\n",
    "$$\n",
    "\\tilde W^{\\mP}_t(u) := \\sqrt{2\\,H}\\,\\int_t^u\\,\\frac{dW^{\\mP}_s}{(u-s)^\\gamma}\n",
    "$$\n",
    "\n",
    "With \n",
    "$\\eta := 2\\,\\nu\\,C_H/\\sqrt{2\\,H}$ we have $2\\,\\nu\\,C_H\\, M_t(u)\n",
    "= \\eta\\, \\tilde W^{\\mP}_t(u)$ so denoting the stochastic exponential by $\\cE(\\cdot)$, we may write\n",
    "\n",
    "$$\n",
    "\\bea\n",
    "v_u &=& v_t \\exp\\left\\{  \\eta \\tilde W^{\\mP}_t(u) +\n",
    " 2\\,\\nu\\,C_H\\, \n",
    "Z_t(u) \\right\\}\\nonumber\\\\\n",
    "&=& \\eefm{v_u}{\\mP}\\,\\cE \\left(\\eta\\,\\tilde W^{\\mP}_t(u) \\right).\n",
    "%\\label{eq:rBergomiP}\n",
    "\\eea\n",
    "$$  \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  - The conditional distribution of $v_u$ depends on $\\cF_t$ only through the variance forecasts $\\eefm{v_u}{\\mP}$, \n",
    " \n",
    " \n",
    " - To price options, one does not need to know $\\cF_t$, the entire history of the Brownian motion $W_s^{\\mP}$ for $s<t$.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Pricing under $\\mQ$\n",
    "\n",
    "Our model under $\\mP$ reads:\n",
    "\n",
    "<a name=\"eq:Pmodel\"></a>(2)\n",
    "$$\n",
    "v_u =\\eefm{v_u}{\\mP}\\,\\cE\\left(\\eta\\,\\tilde W^{\\mP}_t(u) \\right).\n",
    "%\\label{eq:Pmodel}\n",
    "$$\n",
    "\n",
    "Consider some general change of measure\n",
    "\n",
    "$$\n",
    "dW^{\\mP}_s = dW^{\\mQ}_s + \\lambda_s\\,ds,\n",
    "%\\label{eq:dQdP}\n",
    "$$\n",
    "\n",
    "where $\\{ \\lambda_s: s > t \\}$  has a natural interpretation as the price of volatility risk.  We may then rewrite [(2)](#eq:Pmodel) as\n",
    "\n",
    "$$\n",
    "v_u\n",
    "=  \\eefm{v_u}{\\mP}\\,\\cE\\left(\\eta\\,\\tilde W^{\\mQ}_t(u) \\right)\n",
    "\\exp \\left\\{ \\eta\\,\\sqrt{2\\,H}\\, \\int_t^u\\,\\frac{\\lambda_s}{(u-s)^\\gamma}\\,ds\\right\\}.\n",
    "%\\label{eq:explicitBergomiQ1}\n",
    "$$\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Although the conditional distribution of $v_u$ under $\\mP$ is lognormal, it will not be lognormal in general under $\\mQ$.  \n",
    " \n",
    "  - The upward sloping smile in VIX options means $\\lambda_s$ cannot be deterministic in this picture."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The rough Bergomi (rBergomi) model\n",
    "\n",
    "Let's nevertheless consider the simplest change of measure \n",
    "\n",
    "$$\n",
    "d{W}^{\\mP}_s = d{W}^{\\mQ}_s + \\lambda(s)\\,ds, \n",
    "$$\n",
    "\n",
    "where $\\lambda(s)$ is a deterministic function of $s$.  Then from [(2)](#eq:Pmodel), we would have\n",
    "\n",
    "$$\n",
    "\\bea\n",
    "v_u \n",
    "&=&  \\eefm{v_u}{\\mP}\\,\\cE\\left(\\eta\\,\\tilde W^{\\mQ}_t(u) \\right)\n",
    "\\exp \\left\\{ \\eta\\,\\sqrt{2\\,H}\\,  \\int_t^u\\,\\frac{1}{(u-s)^\\gamma}\\,\\lambda(s)\\,ds\\right\\}\\nonumber\\\\\n",
    "&=& \\xi_t(u) \\,\\cE\\left(\\eta\\,\\tilde W^{\\mQ}_t(u) \\right)%\\label{eq:explicitBergomiQ}\n",
    "\\eea\n",
    "$$\n",
    "\n",
    "where the forward variances $\\xi_t(u) =  \\eefm{v_u}{\\mQ}$ are (at least in principle) tradable and  observed in the market.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  -  $\\xi_t(u)$ is the product of two terms:\n",
    "  \n",
    "  - $ \\eefm{v_u}{\\mP}$ which depends on the historical path $\\{W_s, s<t \\}$ of the Brownian motion\n",
    "  - a term which depends on the price of risk $\\lambda(s)$.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features of the rough Bergomi model\n",
    "\n",
    "\n",
    " - The rBergomi model is a non-Markovian generalization of the Bergomi model:\n",
    "$$\n",
    "\\eef{v_u}\\neq \\E[v_u|v_t].\n",
    "$$\n",
    "    - The rBergomi model is Markovian in the (infinite-dimensional) state vector $\\eefm{v_u}{\\mQ}=\\xi_t(u)$.\n",
    "\n",
    "\n",
    "  - We have achieved our earlier aim of replacing the exponential kernels in the Bergomi model with a power-law kernel.  \n",
    " \n",
    "- We may therefore expect that the rBergomi model will generate a realistic term structure of ATM volatility skew."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Re-interpretation of the conventional Bergomi model\n",
    "\n",
    " \n",
    "  - A conventional $n$-factor Bergomi model is not self-consistent for an arbitrary choice of the initial forward variance curve $\\xi_t(u)$.\n",
    " \n",
    " - $\\xi_t(u)=\\eef{v_u}$ should be consistent with the assumed dynamics.\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Viewed from the perspective of the fractional Bergomi model however:\n",
    " \n",
    "  - The initial curve $\\xi_t(u)$ reflects the history $\\{W_s; s<t\\}$ of the driving Brownian motion up to time $t$.\n",
    "  - The exponential kernels in the exponent of the conventional Bergomi model approximate more realistic power-law kernels.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  - The conventional two-factor Bergomi model is then justified in practice as a tractable Markovian engineering approximation to a more realistic fractional Bergomi model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The stock price process\n",
    "\n",
    " \n",
    "- The observed anticorrelation between price moves and volatility moves may be  modeled naturally by anticorrelating the Brownian motion $W$ that drives the volatility process with the Brownian motion driving the price process.  \n",
    "\n",
    "\n",
    "- Thus\n",
    "$$\n",
    "\\frac{dS_t}{S_t}=\\sqrt{v_t}\\,dZ_t\n",
    "$$\n",
    "with\n",
    "$$\n",
    "dZ_t = \\rho\\,dW_t + \\sqrt{1-\\rho^2}\\,dW^\\perp_t\n",
    "$$\n",
    "where $\\rho$ is the correlation between volatility moves and price moves.\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Simulation of the  rBergomi model\n",
    "\n",
    "We simulate the rBergomi model as follows:\n",
    " \n",
    "\n",
    "\n",
    "- Construct the  joint covariance matrix for the Volterra process $\\tilde\n",
    "  W$ and the Brownian motion $Z$ and compute its Cholesky decomposition.\n",
    "\n",
    "\n",
    "- For each time, generate iid normal random vectors and\n",
    "    multiply them by the lower-triangular matrix obtained by the Cholesky\n",
    "    decomposition to get a $m \\times 2\\,n$ matrix of paths of $\\tilde W$     and $Z$ with the correct joint marginals."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- With these paths held in memory, we may evaluate the expectation under $\\mQ$ of any payoff of interest.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- This procedure is very slow!  We need a faster computation.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Hybrid simulation of BSS processes\n",
    "\n",
    "- The Rough Bergomi variance process is a special case of a Brownian Semistationary (BSS) process.\n",
    "\n",
    "\n",
    "- <span>[Bennedsen, Lunde and Pakkanen]<sup id=\"cite_ref-BLP\" class=\"reference\"><a href=\"#cite_note-BLP\"><span>[</span>5<span>]</span></a></sup> show how to simulate such processes more efficiently.\n",
    "    \n",
    "    \n",
    "- More recently, [McCrickerd and Pakkanen]<sup id=\"cite_ref-Turbo\" class=\"reference\"><a href=\"#cite_note-Turbo\"><span>[</span>15<span>]</span></a></sup> show how to massively increasing the efficiency of the hybrid scheme.\n",
    "    - Moreover, they provide a sample Jupyter notebook!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Their idea is roughly as follows:\n",
    "$$\n",
    "\\beas\n",
    "\\int_t^u\\,\\frac{dW_s}{(u-s)^\\gamma} &=& \\sum_{k=1}^{n}\\, \\int_{t_{k+1}}^{t_k}\\,\\frac{dW_s}{(u-s)^\\gamma}\\\\ &\\approx&\n",
    "\\sum_{k=1}^{\\kappa}\\, \\int_{t_{k+1}}^{t_k}\\,\\frac{dW_s}{(u-s)^\\gamma} + \\sum_{k=\\kappa+1}^n\\,\\frac{1}{(u-s_k)^\\gamma}\\, \\int_{t_{k+1}}^{t_k}\\,dW_s\\\\\n",
    "&=&\n",
    "\\sum_{k=1}^{\\kappa}\\, \\int_{t_{k+1}}^{t_k}\\,\\frac{dW_s}{(u-s)^\\gamma} + \\sum_{k=\\kappa+1}^n\\,\\frac{1}{(u-s_k)^\\gamma}\\, Z_k\\,\\sqrt{\\frac{u-t}{n}}\n",
    "\\eeas\n",
    "$$\n",
    "where\n",
    "$\n",
    "t_k = u - \\frac k n (u-t)\n",
    "$,\n",
    "the $Z_k$ are iid $N(0,1)$ random variables and the \n",
    "$\n",
    "s_k  \n",
    "$\n",
    "are such that\n",
    "$$\n",
    "\\int_{t_{k+1}}^{t_k}\\,\\frac{ds}{(u-s)^\\gamma} = \\frac{1}{(u-s_k)^\\gamma}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- The choice $\\kappa =1$ works well in practice.\n",
    "- The choice $\\kappa = 0$ corresponds to the Euler scheme which as expected performs poorly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Guessing rBergomi model parameters\n",
    "\n",
    " \n",
    "- The rBergomi model has only three parameters: $H$, $\\eta$ and $\\rho$.\n",
    "\n",
    "\n",
    "- If we had a fast simulation, we could just iterate on these parameters to find the best fit to observed option prices.  But we don't."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- However, the model parameters $H$, $\\eta$ and $\\rho$ have very direct interpretations:\n",
    " \n",
    "    - $H$ controls the decay of ATM skew $\\psi(\\tau)$ for very short expirations.\n",
    "    \n",
    "    - The product $\\rho\\,\\eta$ sets the level of the ATM skew for longer expirations.\n",
    "    \n",
    "      - Keeping  $\\rho\\,\\eta$ constant but decreasing $\\rho$ (so as to make it more negative) pushes the minimum of each smile towards higher strikes. \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- So we can guess parameters in practice.\n",
    "\n",
    "\n",
    "- As we will see, even without proper calibration (*i.e.* just guessing parameters), rBergomi model fits to the volatility surface are amazingly good."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SPX smiles in the rBergomi model\n",
    "\n",
    " \n",
    "- In Figures 13 and 14, we show how well a rBergomi model simulation with guessed parameters fits the SPX option market as of August 14, 2013, one trading day before the third Friday expiration.\n",
    "\n",
    "\n",
    "- Options set at the open of August 16, 2013 so only one trading day left.\n",
    "    - rBergomi parameters were: $H=0.05$, $\\eta=2.3$, $\\rho=-0.9$.\n",
    "    - Only three parameters to get a very good fit to the whole SPX volatility surface!\n",
    "\n",
    "\n",
    "- Note in particular that the extreme short-dated smile is well reproduced by the rBergomi model.\n",
    "    - There is no need to add jumps!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### SPX smiles as of August 14, 2013\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2015/02/spxSmiles20130814-05.png\" align = \"left\" width=900></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 14: Red and blue points represent bid and offer SPX implied volatilities; orange smiles are from the rBergomi simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The one-month SPX smile as of August 14, 2013\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2017/07/Paris2017smiles20130814-1m.png\" align = \"left\" width=1200></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 15: Red and blue points represent bid and offer SPX implied volatilities; orange smile is from the rBergomi simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### ATM volatilities and skews\n",
    "In Figures 16 and 17, we see just how well the rBergomi model can match empirical skews and vols.  Recall also that the parameters we used are just guesses!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term structure of ATM skew as of August 14, 2013\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2017/07/Paris2017atmSkew20130814.png\" align = \"left\" width=1200></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 16: Blue points are empirical skews; the red line is from the rBergomi simulation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Term structure of ATM vol as of August 14, 2013\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2017/07/Paris2017atmVols20130814.png\" align = \"left\" width=1200></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 17: Blue points are empirical ATM volatilities; green points are from the rBergomi simulation. The two match very closely, as they should. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### VIX options and futures under rough Bergomi\n",
    "\n",
    "- The rough Bergomi model generates more or less flat VIX smiles.\n",
    "    - Inconsistent with observed VIX smiles.\n",
    "    \n",
    "    \n",
    "- Nevertheless, we can still try to impute the rough Bergomi parameters $H$ and $\\eta$ by examining the term structure of VIX futures.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The distribution of VIX future payoffs\n",
    "\n",
    "\n",
    "- Denote the terminal value of the VIX futures by $\\sqrt{\\zeta(T)}$.  Then, by definition (see Chapter 11 of <span>[The Volatility Surface]<sup id=\"cite_ref-TVS\" class=\"reference\"><a href=\"#cite_note-TVS\"><span>[</span>8<span>]</span></a></sup> for more details),\n",
    "<p>\n",
    "$$\n",
    "\\zeta(T)= \\frac{1}{\\Delta}\\,\\int_T^{T+\\Delta}\\,\\E[v_u|\\cF_T]\\,du.\n",
    "$$\n",
    "<p>\n",
    "where $\\Delta$ is one month.\n",
    "\n",
    "\n",
    "\n",
    "- In the rough Bergomi model,\n",
    "<p>\n",
    "$$\n",
    "v_u = \\xi_t(u)\\,\\cE\\left(\\eta\\,\\sqrt{2\\,H}\\,\\int_t^u\\frac{dW_s}{(u-s)^\\gamma}\\right)\n",
    "$$\n",
    "<p>\n",
    "with $\\gamma=1/2-H$ so $v_u$ is lognormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The lognormal approximation\n",
    "\n",
    "\n",
    "- The VIX payoff and its square $\\zeta(T)$ should be approximately lognormally distributed.\n",
    "    -  The quality of this approximation was confirmed by <span>[Jacquier, Martini and Muguruza]<sup id=\"cite_ref-JMM\" class=\"reference\"><a href=\"#cite_note-JMM\"><span>[</span>12<span>]</span></a></sup>.\n",
    "    - In that case, the terminal distribution of $\\zeta(T)$ is completely determined by $\\eef{\\zeta(T)}$ and $\\var[\\log \\zeta(T)|\\cF_t]$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Obviously\n",
    "<p>\n",
    "$$\n",
    "\\eef{\\zeta(T)} = \\frac{1}{\\Delta}\\,\\int_T^{T+\\Delta}\\,\\xi_t(u)\\,du.\n",
    "$$\n",
    "<p>\n",
    "    - Recall that forward variances $\\xi_t(u)$ may be estimated from variance swaps which can themselves be proxied by the log-strip (see Chapter 11 of <span>[The Volatility Surface]<sup id=\"cite_ref-TVS\" class=\"reference\"><a href=\"#cite_note-TVS\"><span>[</span>8<span>]</span></a></sup> again).\n",
    "    \n",
    "    - Alternatively they may be estimated from linear strips of VIX options."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Approximating the conditional variance of $\\zeta(T)$\n",
    "\n",
    "\n",
    "- To estimate the conditional variance of $\\zeta(T)$, we approximate the arithmetic mean by the geometric mean as follows:\n",
    "<p>\n",
    "$$\n",
    "\\zeta(T) \\approx \\exp\\left\\{\\frac{1}{\\Delta}\\,\\int_T^{T+\\Delta}\\,\\E[\\log v_u|\\cF_T]\\,du\\right\\}.\n",
    "$$\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Let $y_u = \\log v_u$ and recall that $\\gamma = \\frac12 - H$.  Apart from $\\mathcal{F}_t$ measurable terms (abbreviated as ``drift''), we have\n",
    "\n",
    "$$\n",
    "\\beas\n",
    "  \\int_T^{T+\\Delta} E[y_u|\\mathcal{F}_T]\\, du &=& \\eta \\sqrt{2H} \\int_t^T\n",
    "  \\frac{dW_s}{(u-s)^\\gamma} du + \\text{drift}\\\\\n",
    "  &=& \\eta \\sqrt{2H} \\int_t^T\n",
    "  \\int_T^{T+\\Delta}  \\frac{du}{(u-s)^\\gamma} dW_s + \\text{drift} \\\\\n",
    "  &=& \\eta \\frac{\\sqrt{2H}}{1-\\gamma} \\int_t^T \\left[ (T+\\Delta-s)^{1-\\gamma} - (T-s)^{1-\\gamma}\n",
    "  \\right] dW_s + \\text{drift}.\n",
    "\\eeas\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "This gives\n",
    "\n",
    "$$\n",
    "\\beas\n",
    "  \\var[\\log \\zeta(T) | \\mathcal{F}_t] &\\approx& \\frac{\\eta^2\n",
    "    }{\\Delta^2} \\,\\frac{2 H}{(H+1/2)^2}\\,\\int_t^T \\left[(T+\\Delta-s)^{1/2+H} - (T-s)^{1/2+H}\n",
    "  \\right]^2 ds\\\\\n",
    "  &=& \\eta^2\\,(T-t)^{2\\,H}\\,f^H\\left(\\frac{\\Delta}{T-t}\\right)\n",
    "\\eeas\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "f^H(\\theta) = \\frac{2 H}{(H+1/2)^2}\\,\\frac{1}{\\theta^2}\\, \\int_0^1\\,\\left[(1+\\theta-x)^{1/2+H} - (1-x)^{1/2+H}\n",
    "  \\right]^2 dx.\n",
    "$$\n",
    "<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The approximate fair value of VIX futures\n",
    "\n",
    "- In <span>[Bayer, Friz and Gatheral]<sup id=\"cite_ref-BFG\" class=\"reference\"><a href=\"#cite_note-BFG\"><span>[</span>2<span>]</span></a></sup>, we chose to study the term structure of VVIX (the VIX of VIX).\n",
    "\n",
    "\n",
    "- It is more natural to follow <span>[Jacquier, Martini and Muguruza]<sup id=\"cite_ref-JMM\" class=\"reference\"><a href=\"#cite_note-JMM\"><span>[</span>9<span>]</span></a></sup> and approximate the fair value of VIX futures.\n",
    "\n",
    "\n",
    "- Under the lognormal approximtion, the fair value of the $T$-maturity VIX future is given by\n",
    "<p>\n",
    "$$\n",
    "\\eef{\\sqrt{\\zeta(T)}} = \\sqrt{\\eef{\\zeta(T)}}\\,\\exp\\left\\{ -\\frac18\\,V_t(T)  \\right\\}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Results\n",
    "\n",
    "- Both [Bayer, Friz and Gatheral]<sup id=\"cite_ref-BFG\" class=\"reference\"><a href=\"#cite_note-BFG\"><span>[</span>2<span>]</span></a></sup> and  <span>[Jacquier, Martini and Muguruza]<sup id=\"cite_ref-JMM\" class=\"reference\"><a href=\"#cite_note-JMM\"><span>[</span>9<span>]</span></a></sup> find that the volatility of volatility parameter $\\eta$ estimated by calibration to the SPX is roughly 20% greater than the estimate from VIX futures and options.\n",
    "    - Arbitrage or model mis-specification?\n",
    "    \n",
    "    \n",
    "- However, calibration to VIX futures is a very quick and practical way of fixing $H$.\n",
    "\n",
    "\n",
    "- If $H$ is fixed, calibration using the Hybrid BSS scheme becomes fast and efficient.\n",
    "    - The expensive part is the simulation of $W^H$ which is fixed if $H$ is fixed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Rough Bergomi parameters under $\\mP$ and under $\\mQ$\n",
    "\n",
    "- We might wonder whether implied model parameters are consistent with historical parameters.\n",
    "\n",
    "\n",
    "- It is shown in   <span>[Bayer, Friz and Gatheral]<sup id=\"cite_ref-BFG\" class=\"reference\"><a href=\"#cite_note-BFG\"><span>[</span>2<span>]</span></a></sup> that the volatility of volatility parameter $\\eta$ in the rough Bergomi model and the volatility of volatility $\\nu$ in the historical time series should be related as follows.\n",
    "<p>\n",
    "$$\n",
    "\\tilde \\eta := \\eta\\,\\sqrt{2\\,H} = 2\\,\\nu\\,C_H\n",
    "$$\n",
    "<p>\n",
    "with\n",
    "<p>\n",
    "$$\n",
    "C_H = \\sqrt{ \\frac{2\\,H\\,\\Gamma(3/2-H)}{\\Gamma(H+1/2)\\,\\Gamma(2-2\\,H)}}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameter estimates under $\\mQ$\n",
    "\n",
    "In Section 5.2 of  <span>[Bayer, Friz and Gatheral]<sup id=\"cite_ref-BFG\" class=\"reference\"><a href=\"#cite_note-BFG\"><span>[</span>2<span>]</span></a></sup>, parameter guesses for the SPX implied volatility surface on two particular dates in history are given as follows:\n",
    "\n",
    "\n",
    "Date  | $H$ | $\\eta$ | $\\tilde \\eta$\n",
    ":------ | -------------: | --------: | --------:\n",
    "February 4, 2010 | 0.07 | 1.9 | 0.7109 \n",
    "August 14, 2013 | 0.05 | 2.3 |  0.7273 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- Estimates of $\\tilde \\eta$ seem more stable than estimates of $\\eta$ and $H$ separately.  \n",
    "\n",
    "\n",
    "- We observe the same phenomenon when estimating $\\nu$ and $H$ from historical RV data.\n",
    "    - Estimates of the product $\\nu \\,\\sqrt{H}$ are more stable than estimates of the two parameters separately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Parameter estimates under $\\mP$\n",
    "\n",
    "- From our analysis of the SPX realized variance time series, we estimated\n",
    "<p>\n",
    "<p>\n",
    "$$\n",
    "H \\approx 0.15, \\quad \\nu \\approx 0.30.\n",
    "$$\n",
    "<p>\n",
    "\n",
    "- Plugging these estimates into the formula (from above)\n",
    "<p>\n",
    "$$\n",
    "\\tilde \\eta_1 = 2\\,\\nu\\,\\sqrt{ \\frac{2\\,H\\,\\Gamma(3/2-H)}{\\Gamma(H+1/2)\\,\\Gamma(2-2\\,H)}} \\approx 0.25.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "h.est <- 0.15\n",
    "nu.est <- 0.3\n",
    "(nu.tilde <- 2*nu.est*sqrt(2*h.est*gamma(3/2-h.est)/gamma(h.est+1/2)*gamma(2-2*h.est)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Seemingly inconsistent with the implied estimate of around $0.7$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- However, the historical estimate is in daily terms and the implied estimate in annualized terms.  \n",
    "\n",
    "\n",
    "- To convert, we need to multiply the historical estimate by the annualization factor $(252)^H$, to get\n",
    "<p>\n",
    "$$\n",
    "\\tilde \\eta \\approx \\tilde \\eta_1 \\times (252)^H = 0.58.\n",
    "$$\n",
    "<p>\n",
    "    - At least by physicists' standards, the historical and implied estimates are consistent.\n",
    "\n",
    "\n",
    "- It is not unexpected for implied volatility of volatility to be higher than historical to reflect the volatility of the volatility risk premium."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Forecasting the variance swap curve\n",
    "\n",
    "Finally, we forecast the whole variance swap curve using the variance forecasting formula [(3)](#eq:vForecast).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "library(stinepack)\n",
    "\n",
    "xi1 <- function(date,nu,h,dt, tscale){ # dt=(u-t) is in units of years\n",
    "  xi <- rv.forecast.XTS(spx.rk,h=h,date=date,nLags=500,delta=dt*tscale,nu)\n",
    "  return(xi)\n",
    "}\n",
    "\n",
    "# Forward variance curve (again the array tt should be in units of years)\n",
    "xi <- function(date,tt,nu,h, tscale){sapply(tt,function(x){xi1(date,nu=nu,h=h,x,tscale)})}\n",
    "\n",
    "\n",
    "nu <- OxfordH$nu.est[1]\n",
    "h <- OxfordH$h.est[1]\n",
    "\n",
    "varSwapCurve <- function(date,bigT,nSteps,nu,h,tscale,onFactor){\n",
    "  # Make vector of fwd variances\n",
    "  tt <- seq(0,bigT,length.out=(nSteps+1))\n",
    "  dt <- tt[2]\n",
    "  xicurve <- xi(date,tt,nu,h,tscale)\n",
    "  xicurve.mid <- (xicurve[1:nSteps]+xicurve[2:(nSteps+1)])/2\n",
    "  int.xicurve <- cumsum(xicurve.mid)*dt\n",
    "  varcurve <- int.xicurve/tt[-1]\n",
    "  varcurve <- c(xicurve[1], varcurve)*onFactor*tscale #onFactor is to compensate for overnight moves\n",
    "  res <- data.frame(tt,sqrt(varcurve))\n",
    "  names(res) <- c(\"texp\",\"vsQuote\")\n",
    "  return(res)\n",
    "}\n",
    "\n",
    "varSwapForecast <- function(date,tau,nu,h,tscale,onFactor){\n",
    "  vsc <- varSwapCurve(date,bigT=2.5,nSteps=100,nu=nu,h=h,tscale,onFactor) # Creates the whole curve\n",
    "  x <- vsc$texp\n",
    "  y <- vsc$vsQuote\n",
    "  res <- stinterp(x,y,tau)$y\n",
    "  return(res)\n",
    "}\n",
    "\n",
    "# Test the function\n",
    "tau <- c(.25,.5,1,2)\n",
    "date <- \"2008-09-08\"\n",
    "varSwapForecast(date,tau,nu=nu,h=h,tscale=252,onFactor=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Constructing a time series of variance swap curves\n",
    "\n",
    "For each of 2,658 days from Jan 27, 2003 to August 31, 2013:\n",
    " \n",
    "  - We compute proxy variance swaps from closing prices of SPX options sourced from OptionMetrics (www.optionmetrics.com) via WRDS.\n",
    "  \n",
    "  \n",
    "  - We form the forecasts $\\eefm{v_u}{\\mP}$ using [(3)](#eq:vForecast) with 500 lags of SPX RV data sourced from The Oxford-Man Institute of Quantitative Finance (http://realized.oxford-man.ox.ac.uk).\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    " \n",
    "   - We note that the actual variance swap curve is a factor (of roughly 1.4) higher than the forecast, which we may attribute to a combination of overnight movements of the index and the price of volatility risk.\n",
    " \n",
    " \n",
    " - Forecasts must therefore be rescaled to obtain close-to-close realized variance forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### 3-month forecast vs actual variance swaps\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2015/02/vsfa3m.png\" align = \"left\" width=900></h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 18: Actual (proxy) 3-month variance swap quotes in blue vs forecast in red (with no scaling factor)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Ratio of actual to forecast\n",
    "\n",
    "<h3><img src=\"http://mfe.baruch.cuny.edu/wp-content/uploads/2015/02/3mratio.png\" align = \"left\" width=900></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 19: The ratio between 3-month actual variance swap quotes and 3-month forecasts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Lehman weekend\n",
    "\n",
    " \n",
    "  -  Empirically, it seems that the variance curve is a simple scaling factor times the forecast, but that this scaling factor is time-varying.\n",
    "  \n",
    "      - We can think of this factor as having two multiplicative components: the overnight factor, and the price of volatility risk.\n",
    "\n",
    "\n",
    "\n",
    "  - Recall that as of the close on Friday September 12, 2008, it was widely believed that Lehman Brothers would be rescued over the weekend. By Monday morning, we knew that Lehman had failed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "- In Figure 19, we see that variance swap curves just before and just after the collapse of Lehman are just rescaled versions of the RFSV forecast curves.\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### We need variance swap estimates for 12-Sep-2008 and 15-Sep-2008\n",
    "\n",
    "We proxy these by taking SVI fits for the two dates and computing the log-strips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "varSwaps12 <- c(\n",
    "    0.2872021, 0.2754535, 0.2601864, 0.2544684, 0.2513854, 0.2515314,\n",
    "    0.2508418, 0.2520099, 0.2502763, 0.2503309, 0.2580933, 0.2588361, \n",
    "    0.2565093)\n",
    "\n",
    "texp12 <- c(\n",
    "    0.01916496, 0.04654346, 0.09582478, 0.19164956, 0.26830938, 0.29842574,\n",
    "    0.51745380, 0.54483231, 0.76659822, 0.79397673, 1.26488706, 1.76317591, \n",
    "    2.26146475)\n",
    "\n",
    "varSwaps15 <-  c(\n",
    "    0.4410505, 0.3485560, 0.3083603, 0.2944378, 0.2756881, 0.2747838, \n",
    "    0.2682212, 0.2679770, 0.2668113, 0.2706713, 0.2729533, 0.2689598, \n",
    "    0.2733176)\n",
    "\n",
    "texp15 <- c(\n",
    "    0.01095140, 0.03832991, 0.08761123, 0.18343600, 0.26009582, 0.29021218, \n",
    "    0.50924025, 0.53661875, 0.75838467, 0.78576318, 1.25667351, 1.75496235, \n",
    "    2.25325120)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Actual vs predicted over the Lehman weekend\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "nu <- OxfordH$nu.est[1]\n",
    "h <- OxfordH$h.est[1]\n",
    "\n",
    "# Variance curve fV model forecasts\n",
    "tau1000 <- seq(0,2.5,length.out=1001)[-1]\n",
    "vs1 <- varSwapForecast(\"2008-09-12\",tau1000,nu=nu,h=h,tscale=252,onFactor=1.29)\n",
    "vs2 <- varSwapForecast(\"2008-09-15\",tau1000,nu=nu,h=h,tscale=252,onFactor=1.29)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Plot results\n",
    "plot(texp12,varSwaps12,type=\"b\",col=\"red\",ylim=c(0.2,0.45),xlab=\"Maturity\",ylab=\"Variance swap quote\",lwd=2)\n",
    "lines(texp15,varSwaps15,type=\"b\",col=\"blue\",lwd=2)\n",
    "lines(tau1000,vs1,col=\"red\",type=\"l\",lty=2,lwd=2)\n",
    "lines(tau1000,vs2,col=\"blue\",type=\"l\",lty=2,lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 20: SPX variance swap curves as of September 12, 2008 (red) and September 15, 2008 (blue). The dashed curves are RFSV model forecasts rescaled by the 3-month ratio ($1.29$) as of the Friday close."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Remarks\n",
    "\n",
    "We note that\n",
    " \n",
    "  - The actual variance swaps curves are very close to the forecast curves, up to a scaling factor.\n",
    "  \n",
    "  \n",
    "  - We are able to explain the change in the variance swap curve with only one extra observation: daily variance over the trading day on Monday 15-Sep-2008. \n",
    " \n",
    " \n",
    " - The SPX options market appears to be backward-looking in a very sophisticated way.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The Flash Crash\n",
    "\n",
    " \n",
    "- The so-called Flash Crash of Thursday May 6, 2010 caused  intraday realized variance to be much higher than normal.   \n",
    "  \n",
    "  \n",
    "- In Figure 19, we plot the actual variance swap curves as of the Wednesday and Friday market closes together with forecast curves rescaled by the 3-month ratio as of the close on Wednesday May 5 (which was $2.52$).  \n",
    "  \n",
    "  \n",
    "- We see that the actual variance curve as of the close on Friday is consistent with a forecast from the time series of realized variance that *includes* the anomalous price action of Thursday May 6. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variance swap estimates \n",
    "\n",
    "We again proxy variance swaps for 05-May-2010, 07-May-2010 and 10-May-2010 by taking SVI fits for the three dates and computing the log-strips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "varSwaps5 <- c(\n",
    "    0.4250369, 0.2552473, 0.2492892, 0.2564899, 0.2612677, 0.2659618, 0.2705928, 0.2761203,\n",
    "    0.2828139, 0.2841165, 0.2884955, 0.2895839, 0.2927817, 0.2992602, 0.3116500)\n",
    "\n",
    "texp5 <- c(\n",
    "    0.002737851, 0.043805613, 0.120465435, 0.150581793, 0.197125257, 0.292950034,\n",
    "    0.369609856, 0.402464066, 0.618754278, 0.654346338, 0.867898700, 0.900752909,\n",
    "    1.117043121, 1.615331964, 2.631074606)\n",
    " \n",
    "varSwaps7 <- c(\n",
    "    0.5469727, 0.4641713, 0.3963352, 0.3888213, 0.3762354, 0.3666858, 0.3615814, 0.3627013,\n",
    "    0.3563324, 0.3573946, 0.3495730, 0.3533829, 0.3521515, 0.3506186, 0.3594066)\n",
    "\n",
    "texp7 <- c(\n",
    "    0.01642710, 0.03832991, 0.11498973, 0.14510609, 0.19164956, 0.28747433, 0.36413415,\n",
    "    0.39698836, 0.61327858, 0.64887064, 0.86242300, 0.89527721, 1.11156742, 1.60985626,\n",
    "    2.62559890)\n",
    "\n",
    "varSwaps10 <- c(\n",
    "    0.3718439, 0.3023223, 0.2844810, 0.2869835, 0.2886912, 0.2905637, 0.2957070, 0.2960737,\n",
    "    0.3005086, 0.3031188, 0.3058492, 0.3065815, 0.3072041, 0.3122905, 0.3299425)\n",
    "\n",
    "texp10 <- c(\n",
    "    0.008213552, 0.030116359, 0.106776181, 0.136892539, 0.183436003, 0.279260780,\n",
    "    0.355920602, 0.388774812, 0.605065024, 0.640657084, 0.854209446, 0.887063655,\n",
    "    1.103353867, 1.601642710, 2.617385352)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Variance curve fV model forecasts\n",
    "vsf5 <- varSwapCurve(\"2010-05-05\",bigT=2.5,nSteps=100,nu=nu,h=h,tscale=252,onFactor=2.52)\n",
    "vsf7 <- varSwapCurve(\"2010-05-07\",bigT=2.5,nSteps=100,nu=nu,h=h,tscale=252,onFactor=2.52)\n",
    "\n",
    "plot(texp5,varSwaps5,type=\"b\",col=\"red\",xlab=expression(paste(\"Time to maturity \",tau)),ylab=\"Variance swap quote\",lwd=2,ylim=c(0.2,.55))\n",
    "lines(texp7,varSwaps7,type=\"b\",col=\"green4\",lwd=2)\n",
    "legend(\"topright\",inset=.02,c(\"May 5\",\"May 7\"),lty=1,col=c(\"red\",\"green4\"))\n",
    "\n",
    "lines(vsf5,col=\"red\",type=\"l\",lty=2,lwd=2)\n",
    "lines(vsf7,col=\"green4\",type=\"l\",lty=2,lwd=2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 21: SPX variance swap curves as of May 5, 2010 (red) and May 7, 2010 (green). The dashed curves are RFSV model forecasts rescaled by the 3-month ratio ($2.52$) as of the close on Wednesday May 5.  The curve as of the close on May 7 is consistent with the forecast **including** the crazy moves on May 6.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The weekend after the Flash Crash\n",
    "\n",
    "Now we plot forecast and actual variance swap curves as of the close on Friday May 7 and Monday May 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Variance curve fV model forecasts\n",
    "vsf7 <- varSwapCurve(\"2010-05-07\",bigT=2.5,nSteps=100,nu=nu,h=h,tscale=252,onFactor=2.52)\n",
    "vsf10 <- varSwapCurve(\"2010-05-10\",bigT=2.5,nSteps=100,nu=nu,h=h,tscale=252,onFactor=2.52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(texp7,varSwaps7,type=\"b\",col=\"green4\",xlab=expression(paste(\"Time to maturity \",tau)),ylab=\"Variance swap quote\",lwd=2,ylim=c(0.2,.55))\n",
    "lines(texp10,varSwaps10,type=\"b\",col=\"orange\",lwd=2)\n",
    "legend(\"topright\",inset=.02,c(\"May 7\",\"May 10\"),lty=1,col=c(\"green4\",\"orange\"))\n",
    "\n",
    "lines(vsf7,col=\"green4\",type=\"l\",lty=2,lwd=2)\n",
    "lines(vsf10,col=\"orange\",type=\"l\",lty=2,lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 22: The May 10 actual curve is  inconsistent with a forecast that includes the Flash Crash.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Now let's see what happens if we exclude the Flash Crash from the time series used to generate the variance curve forecast. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "flash.day <- which(index(spx.rk)==\"2010-05-06\")\n",
    "spx.rk.p <- spx.rk[-flash.day]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spx.rk.p <- spx.rk[-flash.day]\n",
    "plot.zoo(cbind(spx.rk[\"2010-05-04::2010-05-10\"],spx.rk.p[\"2010-05-04::2010-05-10\"]),type=\"b\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We need a new variance curve forecast function that uses the new time series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "xi1p <- function(date,nu,h,dt, tscale){ # dt=(u-t) is in units of years\n",
    "  xi <- rv.forecast.XTS(spx.rk.p,h=h,date=date,nLags=500,delta=dt*tscale,nu)\n",
    "  return(xi)\n",
    "}\n",
    "\n",
    "# Forward variance curve (again the array tt should be in units of years)\n",
    "xip <- function(date,tt,nu,h, tscale){sapply(tt,function(x){xi1p(date,nu=nu,h=h,x,tscale)})}\n",
    "\n",
    "varSwapCurve.p <- function(date,bigT,nSteps,nu,h,tscale,onFactor){\n",
    "  # Make vector of fwd variances\n",
    "  tt <- seq(0,bigT,length.out=(nSteps+1))\n",
    "  dt <- tt[2]\n",
    "  xicurve <- xip(date,tt,nu,h,tscale)\n",
    "  xicurve.mid <- (xicurve[1:nSteps]+xicurve[2:(nSteps+1)])/2\n",
    "  int.xicurve <- cumsum(xicurve.mid)*dt\n",
    "  varcurve <- int.xicurve/tt[-1]\n",
    "  varcurve <- c(xicurve[1], varcurve)*onFactor*tscale #onFactor is to compensate for overnight moves\n",
    "  res <- data.frame(tt,sqrt(varcurve))\n",
    "  names(res) <- c(\"texp\",\"vsQuote\")\n",
    "  return(res)\n",
    "}\n",
    "\n",
    "varSwapForecast.p <- function(date,tau,nu,h,tscale,onFactor){\n",
    "  vsc <- varSwapCurve.p(date,bigT=2.5,nSteps=100,nu=nu,h=h,tscale,onFactor) # Creates the whole curve\n",
    "  x <- vsc$texp\n",
    "  y <- vsc$vsQuote\n",
    "  res <- stinterp(x,y,tau)$y\n",
    "  return(res)\n",
    "}\n",
    "\n",
    "# Test the function\n",
    "tau <- c(.25,.5,1,2)\n",
    "date <- \"2010-05-10\"\n",
    "varSwapForecast.p(date,tau,nu=nu,h=h,tscale=252,onFactor=1/(1-.35))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Finally, we compare our new forecast curves with the actuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Variance curve fV model forecasts\n",
    "vsf7 <- varSwapCurve(\"2010-05-07\",bigT=2.5,nSteps=100,nu=nu,h=h,tscale=252,onFactor=2.52)\n",
    "vsf10p <- varSwapCurve.p(\"2010-05-10\",bigT=2.5,nSteps=100,nu=nu,h=h,tscale=252,onFactor=2.52)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "plot(texp7,varSwaps7,type=\"b\",col=\"green4\",xlab=expression(paste(\"Time to maturity \",tau)),ylab=\"Variance swap quote\",lwd=2,ylim=c(0.2,.55))\n",
    "lines(texp10,varSwaps10,type=\"b\",col=\"orange\",lwd=2)\n",
    "legend(\"topright\",inset=.02,c(\"May 7\",\"May 10\"),lty=1,col=c(\"green4\",\"orange\"))\n",
    "\n",
    "lines(vsf7,col=\"green4\",type=\"l\",lty=2,lwd=2)\n",
    "lines(vsf10p,col=\"orange\",type=\"l\",lty=2,lwd=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Figure 23: The May 10 actual curve is consistent with a forecast that excludes the Flash Crash."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "###  Resetting of expectations over the weekend  \n",
    "  \n",
    "  -  In Figures 21 and 23, we see that the actual variance swap curve on Monday, May 10  is consistent with a  forecast that excludes the  Flash Crash.\n",
    " \n",
    " \n",
    "  - Volatility traders realized that the Flash Crash should not influence future realized variance projections."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Summary\n",
    "\n",
    " \n",
    "  - We uncovered a remarkable monofractal scaling relationship in historical volatility.\n",
    " \n",
    "  \n",
    "  \n",
    "  - This leads to a natural non-Markovian stochastic volatility model under $\\mP$.\n",
    "  \n",
    "  \n",
    "  - The simplest specification of $\\frac{d\\mQ}{d\\mP}$ gives a non-Markovian generalization of the Bergomi model.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "  \n",
    "  - The history of the Brownian motion $\\lbrace W_s, s<t\\rbrace $ required for pricing is encoded in the forward variance curve, which is observed in the market.\n",
    "  \n",
    "\n",
    "  - This model fits the observed volatility surface surprisingly well with very few parameters.\n",
    " \n",
    " \n",
    " \n",
    "- For perhaps the first time, we have a simple consistent model of historical and implied volatility.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### References  \n",
    "\n",
    "<br />\n",
    "\n",
    "<div class=\"reflist\" style=\"list-style-type: decimal;\">\n",
    "\n",
    "<ol>\n",
    "\n",
    "<li id=\"cite_note-Alos\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Alos\">^</a></b></span> \n",
    "Al√≤s, Elisa, Jorge A Le√≥n, and Josep Vives, On the short-time behavior of the implied volatility for jump-diffusion models with stochastic volatility, *Finance and Stochastics* **11**(4) 571-589 (2007).\n",
    "</li>\n",
    "\n",
    "<li id=\"cite_note-ABDE\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ABDE\">^</a></b></span>\n",
    "Torben G Andersen, Tim Bollerslev, Francis X Diebold, and Heiko Ebens, The distribution of realized stock return volatility, *Journal of Financial Economics* **61**(1) 43-76 (2001).\n",
    "</li>\n",
    "\n",
    "<li id=\"cite_note-BacryMuzy\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-BacryMuzy\">^</a></b></span>\n",
    "Emmanuel Bacry and Jean-Fran√ßois Muzy, Log-infinitely divisible multifractal processes, \n",
    "*Communications in Mathematical Physics* **236**(3) 449-475 (2003).</li>\n",
    "\n",
    "\n",
    "<li id=\"cite_note-BFG\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-BFG\">^</a></b></span> \n",
    "Christian Bayer, Peter Friz and Jim Gatheral, Pricing under rough volatility, *Quantitative Finance* **16**(6) 887-904 (2016).\n",
    "</li>\n",
    " \n",
    "\n",
    "\n",
    " <li id=\"cite_note-BLP\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-BLP\">^</a></b></span>\n",
    "Mikkel Bennedsen, Asger Lunde, and Mikko S. Pakkanen, Hybrid scheme for Brownian semistationary processes, *Finance and Stochastics* **21**(4) 931-965, (2017).</li>\n",
    "\n",
    "<li id=\"cite_note-HCE\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-HCE\">^</a></b></span>\n",
    "Mikkel Bennedsen, Asger Lunde, and Mikko S. Pakkanen, Decoupling the short-and long-term behavior of stochastic volatility, available at https://arxiv.org/abs/1610.00332, (2016).</li>\n",
    "\n",
    "<li id=\"cite_note-ComteRenault\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ComteRenault\">^</a></b></span> \n",
    "Fabienne Comte and Eric Renault, Long memory in continuous-time stochastic volatility models, *Mathematical Finance* **8** 29-323(1998).</li>\n",
    "\n",
    "<li id=\"cite_note-ElEuchRosenbaum\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-ElEuchRosenbaum\">^</a></b></span> \n",
    "Omar El Euch and Mathieu Rosenbaum, The characteristic function of rough Heston models, *Mathematical Finance, forthcoming* (2018).</li>\n",
    "\n",
    "\n",
    "<li id=\"cite_note-Fukasawa\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Fukasawa\">^</a></b></span> \n",
    "Masaaki Fukasawa, Asymptotic analysis for stochastic volatility: Martingale expansion, *Finance and Stochastics* **15** 635-654 (2011).</li>\n",
    "\n",
    "\n",
    "\n",
    "<li id=\"cite_note-GJR\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-GJR\">^</a></b></span> Jim Gatheral, Thibault Jaisson and Mathieu Rosenbaum, Volatility is rough, *Quantitative Finance*, **18**(6) 933-949 (2018).</li>\n",
    "\n",
    "\n",
    "\n",
    "<li id=\"cite_note-GO\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-GO\">^</a></b></span> Jim Gatheral and Roel Oomen, Zero-intelligence realized variance estimation, *Finance and Stochastics* **14**(2) 249-283 (2010).</li> \n",
    "\n",
    "<li id=\"cite_note-JMM\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-JMM\">^</a></b></span> Antoine Jacquier, Claude Martini, and Aitor Muguruza, On VIX Futures in the rough Bergomi model, *Quantitative Finance* **18**(1) 45-61 (2018).</li>\n",
    "\n",
    "\n",
    "<li id=\"cite_note-JaissonRosenbaum\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-JaissonRosenbaum\">^</a></b></span> Thibault Jaisson and Mathieu Rosenbaum, Rough fractional diffusions as scaling limits of nearly unstable heavy tailed Hawkes processes, *The Annals of Applied Probability* **26**(5) 2860-2882 (2016).</li>\n",
    "\n",
    "\n",
    "<li id=\"cite_note-NuzmanPoor\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-NuzmanPoor\">^</a></b></span> Carl J. Nuzman and H. Vincent Poor, Linear estimation of self-similar processes via Lamperti‚Äôs transformation, *Journal of Applied Probability* **37**(2) 429-452 (2000).</li>\n",
    " \n",
    "\n",
    "<li id=\"cite_note-Turbo\"><span class=\"mw-cite-backlink\"><b><a href=\"#cite_ref-Turbo\">^</a></b></span> Ryan McCrickerd and Mikko S Pakkanen, Turbocharging Monte Carlo Pricing for the Rough Bergomi Model, *Quantitative Finance* **18**(11) 1877-1886 (2018).</li>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</ol>\n",
    "\n",
    "\n",
    "  \n",
    "\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
